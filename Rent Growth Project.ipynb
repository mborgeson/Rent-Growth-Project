{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PACKAGE IMPORT LIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################\n",
    "########################################## PYTHON PACKAGES TO IMPORT ##########################################\n",
    "###############################################################################################################\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import enum\n",
    "import winsound\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline\n",
    "\n",
    "\n",
    "import IPython\n",
    "from IPython import get_ipython, paths\n",
    "from IPython.paths import get_ipython_dir, get_ipython_module_path, get_ipython_package_dir\n",
    "from IPython import display, extensions, extract_module_locals, Application\n",
    "from IPython.display import HTML, SVG, YouTubeVideo, set_matplotlib_formats, FileLink, IFrame\n",
    "from IPython.display import display, Pretty, DisplayHandle, DisplayObject\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "# from pylab import *\n",
    "\n",
    "\n",
    "import nbformat\n",
    "from nbformat import read\n",
    "import notebook\n",
    "from notebook import notebookapp, auth, serverextensions, extensions, utils\n",
    "from notebook import nbextensions, nbconvert\n",
    "\n",
    "\n",
    "import ipywidgets\n",
    "from ipywidgets import AppLayout, FloatLogSlider, load_ipython_extension, widgets\n",
    "\n",
    "import ipydatetime\n",
    "import ipyparallel\n",
    "import ipympl\n",
    "import ipyleaflet\n",
    "\n",
    "# import jupyterthemes\n",
    "# from jupyterthemes import get_themes, install_theme, fonts, styles, layout\n",
    "# import jupyterlab_sql\n",
    "# from jupyterlab_sql import load_jupyter_server_extension\n",
    "\n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "import sktime\n",
    "from sktime.datasets import load_airline, load_longley\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "# from sktime.forecasting.arima import AutoARIMA\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.forecasting.theta import ThetaForecaster\n",
    "# from sktime.forecasting.var import VAR\n",
    "from sktime.utils.plotting import plot_series\n",
    "from sktime.datatypes import get_examples\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.performance_metrics.forecasting import mean_absolute_percentage_error\n",
    "from sktime.forecasting.fbprophet import Prophet\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import fastai\n",
    "import rich\n",
    "\n",
    "# import keras\n",
    "# import tensorflow\n",
    "# # Keras API for building and training models\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# # TensorFlow device management (to inspect hardware like GPUs/CPUs)\n",
    "# from tensorflow.python.framework import config \n",
    "# from tensorflow.python.client import device_lib\n",
    "# # TensorFlow build information (for debugging CUDA/cuDNN versions, etc.)\n",
    "# from tensorflow.python.platform import build_info\n",
    "\n",
    "import optuna\n",
    "\n",
    "import openpyxl\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTEBOOK CONFIGURATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPYTHON AND JUPYTER INLINE CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chapter 1 in \"IPYTHON INTERACTIVE COMPUTING AND VISUALIZATION COOKBOOK\" provides references to IPython 'magics' commands ###\n",
    "# %matplotlib inline\n",
    "# %quickref\n",
    "# %magic\n",
    "# %lsmagic\n",
    "# %time?\n",
    "# %timeit?\n",
    "# %%timeit?\n",
    "# %pylab\n",
    "\n",
    "# %load_ext sql\n",
    "# %reload_ext sql\n",
    "# %load_ext [TBD]\n",
    "\n",
    "##### IPYTHON INTERACTIVESHELL CONFIGURATION #####\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# set_matplotlib_formats('png', 'jpeg', 'svg', 'pdf', quality=100)\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('png', 'jpeg', 'svg', 'pdf')\n",
    "\n",
    "\n",
    "##### RESETTING PANDAS DATAFRAME PRINT OPTIONS CONFIGURATION #####\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_columns')\n",
    "pd.reset_option('display.max_colwidth')\n",
    "pd.reset_option('display.width')\n",
    "pd.reset_option('styler.render.max_elements')\n",
    "\n",
    "pd.reset_option('colheader_justify')\n",
    "\n",
    "pd.reset_option('precision')\n",
    "pd.reset_option('display.float_format')\n",
    "# pd.reset_option('all')\n",
    "\n",
    "##### PANDAS DATAFRAME PRINT OPTIONS CONFIGURATION #####\n",
    "pd.set_option('display.max_rows', 25)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_colwidth', 30)\n",
    "pd.set_option('display.width', 30)\n",
    "# pd.set_option('styler.render.max_elements',2500)\n",
    "\n",
    "pd.set_option('colheader_justify','center')\n",
    "\n",
    "# pd.set_option('precision',0)\n",
    "pd.set_option('display.float_format', lambda x: '{:,.0f}'.format(x))\n",
    "pd.set_option('display.float_format', lambda x: '{:,.0f}'.format(x))\n",
    "\n",
    "figsize(10,10)\n",
    "\n",
    "%config Completer.use_jedi = False\n",
    "%config IPCompleter.use_jedi = False\n",
    "\n",
    "# dataframe_export_path = 'C:\\\\Users\\\\mattb\\\\Desktop\\\\Programming\\\\DataFrame Exports\\\\'\n",
    "# pd.io.excel.ExcelWriter(path=dataframe_export_path,engine=\n",
    "\n",
    "# # Set parallelism threads\n",
    "# config.set_inter_op_parallelism_threads(4)  # Number of threads for inter-op parallelism\n",
    "# config.set_intra_op_parallelism_threads(4)  # Number of threads for intra-op parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTEBOOK AND SERVER DIRECTORY INFORMATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADDING CURRENT/WORKING DIRECTORIES TO THE SYS.PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_projects_folder_path = os.path.abspath(r\"C:\\Users\\mattb\\B&R - Python Projects\\1). Current Projects\")\n",
    "# costar_data_import_folder_path = os.path.abspath(r\"C:\\Users\\mattb\\B&R - Python Projects\\1). Current Projects\\H). CoStar Data Import\")\n",
    "\n",
    "\n",
    "# directory_item_list = os.listdir(costar_data_import_folder_path)\n",
    "# directory_path_list = []\n",
    "# ipynb_file_list = []\n",
    "\n",
    "# for directory_item in directory_item_list:\n",
    "#     dir_path = costar_data_import_folder_path + \"\\\\\" + directory_item\n",
    "#     directory_path_list.append(dir_path)\n",
    "#     if os.path.isfile(dir_path):\n",
    "#         ipynb_file_list.append(dir_path)\n",
    "\n",
    "\n",
    "# section_paths_list = [\n",
    "#     current_projects_folder_path,\n",
    "#     costar_data_import_folder_path,]\n",
    "\n",
    "# section_paths_list.extend(directory_path_list)\n",
    "\n",
    "\n",
    "# for path in section_paths_list:\n",
    "#     if sys.path.count(path) > 0:\n",
    "#         sys.path.remove(path)\n",
    "#     else:\n",
    "#         sys.path.append(path)\n",
    "# section_paths_list\n",
    "\n",
    "# # with importnb.imports('ipynb'):\n",
    "# #     import \"CoStar Data Import - Sales Comps\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROJECT FILES AND FOLDERS / WORKING DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook_directory = ''\n",
    "# notebook_working_dir = ''\n",
    "# working_dir_item_list = ''\n",
    "# working_dir_file_list = []\n",
    "# working_dir_folder_list = []\n",
    "# working_dir_dict = {}\n",
    "\n",
    "# notebook_directory = !dir\n",
    "# for dir_item in notebook_directory:\n",
    "#     dir_str = ''\n",
    "#     dir_str = str(dir_item)\n",
    "\n",
    "#     if dir_str.find(\"Directory\") >= 0:\n",
    "#         notebook_working_dir = ''\n",
    "#         notebook_working_dir = dir_str.strip().replace(\"Directory of \", \"\")\n",
    "\n",
    "# os.chdir(notebook_working_dir)\n",
    "\n",
    "# working_dir_tree = !tree / A / F\n",
    "# working_dir_tree = working_dir_tree.get_list()\n",
    "\n",
    "# for item in working_dir_tree:\n",
    "#     if item.find(\"+/--\") >= 0 or item.find(\"\\\\--\") >= 0:\n",
    "#         folder_item = ''\n",
    "#         folder_item = item.replace(\"+---\", \"\").replace(\"\\\\---\", \"\")\n",
    "#         if folder_item.find(\"  \") < 0:\n",
    "#             working_dir_folder_list.append(folder_item)\n",
    "\n",
    "#     elif item.find(\"|   \") >= 0:\n",
    "#         file_item = ''\n",
    "#         file_item = item.replace(\"|   \", \"\")\n",
    "#         if file_item.find(\"  \") < 0:\n",
    "#             working_dir_file_list.append(file_item)\n",
    "\n",
    "\n",
    "# for directory_item in working_dir_file_list:\n",
    "#     if directory_item == '':\n",
    "#         try:\n",
    "#             working_dir_file_list.remove('')\n",
    "#         except:\n",
    "#             None\n",
    "\n",
    "# for directory_item in working_dir_folder_list:\n",
    "#     if directory_item == '':\n",
    "#         try:\n",
    "#             working_dir_folder_list.remove('')\n",
    "#         except:\n",
    "#             None\n",
    "\n",
    "# working_dir_dict.update({\"Directory Path\": notebook_working_dir})\n",
    "# working_dir_dict.update({\"Directory Files\": working_dir_file_list})\n",
    "# working_dir_dict.update({\"Directory Folders\": working_dir_folder_list})\n",
    "\n",
    "# # working_dir_dict\n",
    "# # pyperclip.copy(notebook_working_dir)\n",
    "# # pd.Series(working_dir_dict).to_clipboard()\n",
    "# # pd.Series(working_dir_tree).to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROJECT FILES AND FOLDERS - PROJECT FILES DIRECTORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Files Tree Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_directory = ''\n",
    "# files_directory_output = ''\n",
    "# files_dir_file_list = []\n",
    "# files_dir_folder_list = []\n",
    "# files_dir_dict = {}\n",
    "\n",
    "# files_directory = os.path.abspath(r\"C:\\Users\\mattb\\B&R - Python Projects\\1). Current Projects\\H). CoStar Data Import\\Analyses\\Variable Forecasting\\Data Files\")\n",
    "# files_directory\n",
    "# # support_and_info_directory = ''\n",
    "# os.chdir(files_directory)\n",
    "\n",
    "# files_directory = ''\n",
    "# files_directory_output = ''\n",
    "# files_dir_file_list = []\n",
    "# files_dir_folder_list = []\n",
    "# files_dir_dict = {}\n",
    "\n",
    "# files_directory_output = !dir\n",
    "# for files_dir_item in files_directory_output:\n",
    "#     files_dir_str = ''\n",
    "#     files_dir_str = str(files_dir_item)\n",
    "\n",
    "#     if files_dir_str.find(\"Directory\") >= 0:\n",
    "#         files_working_dir = ''\n",
    "#         files_working_dir = files_dir_str.strip().replace(\"Directory of \", \"\")\n",
    "\n",
    "# files_directory_output\n",
    "# files_dir_tree = !tree / A / F\n",
    "# files_dir_tree = files_dir_tree.get_list()\n",
    "# # files_dir_tree\n",
    "\n",
    "# for item in files_dir_tree:\n",
    "#     if item.find(\"+---\") >= 0 or item.find(\"\\\\--\") >= 0:\n",
    "#         # print(item)\n",
    "#         files_folder_item = ''\n",
    "#         files_folder_item = item.replace(\"+---\", \"\").replace(\"\\\\---\", \"\")\n",
    "#         if files_folder_item.find(\"  \") < 0:\n",
    "#             files_dir_folder_list.append(files_folder_item)\n",
    "\n",
    "#     elif item.find(\"|   \") >= 0 or item.find(\"|   |   \") >= 0 or item.find(\"|           \") >= 0:\n",
    "#         files_folder_item = ''\n",
    "#         files_folder_item = item.replace(\"|   \", \"\").replace(\n",
    "#             \"|   |   \", \"\").replace(\"|           \", \"\")\n",
    "#         if files_folder_item.find(\"  \") < 0:\n",
    "#             files_dir_file_list.append(files_folder_item)\n",
    "\n",
    "# for directory_item in files_dir_file_list:\n",
    "#     if directory_item == '':\n",
    "#         try:\n",
    "#             files_dir_file_list.remove('')\n",
    "#         except:\n",
    "#             None\n",
    "\n",
    "# for directory_item in files_dir_folder_list:\n",
    "#     if directory_item == '':\n",
    "#         try:\n",
    "#             files_dir_folder_list.remove('')\n",
    "#         except:\n",
    "#             None\n",
    "\n",
    "# files_dir_dict.update({\"Directory Path\": files_working_dir})\n",
    "# files_dir_dict.update({\"Directory Files\": files_dir_file_list})\n",
    "# files_dir_dict.update({\"Directory Folders\": files_dir_folder_list})\n",
    "\n",
    "# files_dir_dict\n",
    "\n",
    "# os.chdir(notebook_working_dir)\n",
    "# # pyperclip.copy(notebook_working_dir)\n",
    "# # pd.Series(working_dir_dict).to_clipboard()\n",
    "# # pd.Series(working_dir_tree).to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTEBOOK PROJECT #1 - VARIABLE FORECASTING (MULTIFAMILY RENT GROWTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART A). FILE PATH CONFIGURATION AND CREATING MERGED VARIABLE DATAFRAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.A.1) FILE PATH CONFIGURATION FOR VARIOUS EXCEL DATA FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.A.1.1) FILE PATH CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fred Annual Series Data.xlsx',\n",
       " 'Fred Monthly Series Data.xlsx',\n",
       " 'Rent Growth Forecast (Annual) - Merged Data (Fred Series Data & Phoenix Market Data).xlsx',\n",
       " 'Rent Growth Forecast (Quarterly) - Merged Data (Fred Series Data & Phoenix Market Data).xlsx']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Fred Monthly Series Data.xlsx'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['All Markets - Actuals & Projections (8.23.2024).xlsx',\n",
       " 'All Markets - Actuals (8.23.2024).xlsx',\n",
       " 'Phoenix MSA - Actuals (8.23.2024).xlsx']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'All Markets - Actuals (8.23.2024).xlsx'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################################################################\n",
    "############################### EXCEL DATA FILE PATHS ###############################\n",
    "#####################################################################################\n",
    "user_name = \"MattBorgeson\"\n",
    "\n",
    "fred_data_directory = os.path.abspath(r'C:\\Users\\MattBorgeson\\OneDrive - B&R Capital\\Programming Projects\\Rent Growth Forecasting\\Input Files\\Fred Data')\n",
    "fred_data_file_name_selection = os.listdir(fred_data_directory)[1]\n",
    "fred_data_file_path = os.path.abspath(f'{fred_data_directory}\\\\{fred_data_file_name_selection}')\n",
    "\n",
    "market_analysis_directory = os.path.abspath(r'C:\\Users\\MattBorgeson\\OneDrive - B&R Capital\\Programming Projects\\Rent Growth Forecasting\\Input Files\\Market Analyses')\n",
    "market_analysis_file_name_selection = os.listdir(market_analysis_directory)[1]\n",
    "market_analysis_file_path = os.path.abspath(f'{market_analysis_directory }\\\\{market_analysis_file_name_selection}')\n",
    "\n",
    "\n",
    "os.listdir(fred_data_directory)\n",
    "os.listdir(fred_data_directory)[1]\n",
    "\n",
    "os.listdir(market_analysis_directory)\n",
    "os.listdir(market_analysis_directory)[1]\n",
    "\n",
    "market_analysis_df = pd.read_excel(market_analysis_file_path)\n",
    "fred_data_df = pd.read_excel(fred_data_file_path)\n",
    "# market_analysis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.A.1.2) READING MARKET ANALYSIS & FRED DATA EXCEL FILES INTO A DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #####################################################################################\n",
    "# ##################### READING EXISTING ANALYSES INTO DATAFRAMES #####################\n",
    "# #####################################################################################\n",
    "# os.listdir(fred_data_directory)\n",
    "# os.listdir(market_analysis_directory)\n",
    "\n",
    "# os.listdir(fred_data_directory)[1]\n",
    "# os.listdir(market_analysis_directory)[1]\n",
    "\n",
    "# market_analysis_df = pd.read_excel(market_analysis_file_path)\n",
    "# fred_data_df = pd.read_excel(fred_data_file_path)\n",
    "# # market_analysis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.A.1.3) PYTORCH CHECK ON UTILIZATION OF COMPUTER HARDWARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n",
      "True\n",
      "NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "Using device: cuda\n",
      "Tensor x: tensor([[0.6693, 0.0550, 0.3258],\n",
      "        [0.4254, 0.7451, 0.1669],\n",
      "        [0.0549, 0.9491, 0.4979]], device='cuda:0')\n",
      "Tensor x is on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "#####################################################################################\n",
    "######################## PYTORCH HARDWARE UTILIZATION CHECK #########################\n",
    "#####################################################################################\n",
    "\n",
    "print(torch.__version__)             # Prints the PyTorch version\n",
    "print(torch.cuda.is_available())     # True if a compatible GPU is accessible\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA is not available\")\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Create a random 2D tensor on the selected device\n",
    "x = torch.rand((3, 3), device=device)\n",
    "print(\"Tensor x:\", x)\n",
    "print(\"Tensor x is on:\", x.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.A.2) RENT GROWTH FORECASTING -- QUARTERLY RENT GROWTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.A.2.1) READING SELECTED EXCEL SHEETS INTO A MERGED DATAFRAME (QUARTERLY RENT GROWTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################\n",
    "#################################### CREATE THE MERGED DATAFRAME & EXPORT TO EXCEL ####################################\n",
    "#######################################################################################################################\n",
    "market_analysis_df = pd.read_excel(market_analysis_file_path)\n",
    "fred_data_df = pd.read_excel(fred_data_file_path)\n",
    "\n",
    "\n",
    "merged_data_df = pd.merge(market_analysis_df, fred_data_df, left_on=\"Analysis Date\", right_on=\"Adjusted Analysis Date\", how='inner')\n",
    "merged_data_df.rename(columns={\"Analysis Date_x\":\"Analysis Date\"}, inplace=True)\n",
    "merged_data_df.rename(columns={\"Adjusted Analysis Day\":\"Analysis Day\"}, inplace=True)\n",
    "\n",
    "\n",
    "# analysis_day_col = merged_data_df.pop(\"Analysis Day\")\n",
    "# merged_data_df.insert(3, \"Analysis Day\", analysis_day_col)\n",
    "\n",
    "# merged_data_col_drop_list = [\n",
    "#     \"Analysis Date_y\",\n",
    "#     \"Adjusted Analysis Date\",\n",
    "#     \"Adjusted Analysis Year\",\n",
    "#     \"Adjusted Analysis Month\",\n",
    "#     \"Analysis Year\",\n",
    "#     \"Analysis Month\",\n",
    "#     \"Analysis Day\",\n",
    "#     \"Annual Rent Growth (%)\",\n",
    "#     \"Annual Rent Growth (%) - Lagged\",\n",
    "#     \"Stabilized Vacancy (%)\",\n",
    "#     \"Market Asking Rent/Unit ($)\",\n",
    "# ]\n",
    "\n",
    "# merged_data_df.drop(columns=merged_data_col_drop_list, inplace=True)\n",
    "# merged_data_df\n",
    "\n",
    "\n",
    "\n",
    "merged_data_col_list = [\n",
    "    \"Analysis Date\",\n",
    "    \"Market Name\",\n",
    "\n",
    "    # \"Annual Rent Growth (%)\",\n",
    "    # \"Annual Rent Growth (%) - Lagged\",\n",
    "    \"Quarterly Rent Growth (%)\",\n",
    "    # \"Quarterly Rent Growth (%) - Lagged\",\n",
    "\n",
    "    \"Inventory (# Units)\",\n",
    "    \"Under Construction (# Units)\",\n",
    "    \"Under Construction (% of Inventory)\",\n",
    "    \"Total Occupancy (# Units)\",\n",
    "    \"Total Vacancy (# Units)\",\n",
    "    \n",
    "    \"Quarterly Net Deliveries (# Units)\",\n",
    "    \"Quarterly Construction Starts (# Units)\",\n",
    "    \"Quarterly Net Absorption (# Units)\",\n",
    "    \"Absorption - Prior 12 Months (# Units)\",\n",
    "    \"Net Deliveries - Prior 12 Months (# Units)\",\n",
    "\n",
    "    \"Unemployment Rate (%)\",\n",
    "    \"Job Growth (%)\",\n",
    "    \"Population (#)\",\n",
    "    \"Population Growth (%)\",\n",
    "    \"Median Household Income ($)\",\n",
    "    \"Median Household Income Growth (%)\",\n",
    "\n",
    "    \"Federal Funds Effective Rate\",\n",
    "\n",
    "    \"Consumer Price Index for All Urban Consumers: All Items in U.S. City Average\",\n",
    "\n",
    "    \"Unemployed Persons in Phoenix-Mesa-Scottsdale, AZ (MSA)\",\n",
    "    \"Employed Persons in Phoenix-Mesa-Scottsdale, AZ (MSA)\",\n",
    "    \"Civilian Labor Force in Phoenix-Mesa-Scottsdale, AZ (MSA)\",\n",
    "    \"Unemployment Rate in Phoenix-Mesa-Scottsdale, AZ (MSA)\",\n",
    "\n",
    "    \"S&P CoreLogic Case-Shiller AZ-Phoenix Home Price Index\",\n",
    "]\n",
    "\n",
    "\n",
    "quarterly_forecast_merged_data_df = merged_data_df[merged_data_col_list]\n",
    "\n",
    "quarterly_forecast_merged_data_df = quarterly_forecast_merged_data_df[quarterly_forecast_merged_data_df != '-']\n",
    "quarterly_forecast_merged_data_df[\"Quarterly Rent Growth (%)\"] = quarterly_forecast_merged_data_df[\"Quarterly Rent Growth (%)\"].astype('float')\n",
    "quarterly_forecast_merged_data_df.dropna(inplace=True)\n",
    "quarterly_forecast_merged_data_df.reset_index(inplace=True)\n",
    "quarterly_forecast_merged_data_df.drop(columns=['index'], inplace=True)\n",
    "\n",
    "\n",
    "############ Export the merged Dataframe to Excel\n",
    "quarterly_forecast_merged_data_file_path = os.path.abspath(f'{fred_data_directory}\\\\Rent Growth Forecast (Quarterly) - Merged Data (Fred Series Data & Phoenix Market Data).xlsx')\n",
    "quarterly_forecast_merged_data_df.to_excel(quarterly_forecast_merged_data_file_path, index=False)\n",
    "\n",
    "merged_data_df = merged_data_df[merged_data_col_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.A.2.2) MULTIVARIATE TIME SERIES ANALYSIS (QUARTERLY RENT GROWTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MattBorgeson\\AppData\\Local\\Temp\\ipykernel_52940\\2340681458.py:12: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_filled = merged_data.fillna(method='ffill')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "             estimator=Ridge(), param_grid={&#x27;alpha&#x27;: [0.01, 0.1, 1.0, 10, 100]},\n",
       "             scoring=&#x27;r2&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "             estimator=Ridge(), param_grid={&#x27;alpha&#x27;: [0.01, 0.1, 1.0, 10, 100]},\n",
       "             scoring=&#x27;r2&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: Ridge</label><div class=\"sk-toggleable__content fitted\"><pre>Ridge(alpha=10)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;Ridge<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.Ridge.html\">?<span>Documentation for Ridge</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>Ridge(alpha=10)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "             estimator=Ridge(), param_grid={'alpha': [0.01, 0.1, 1.0, 10, 100]},\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MattBorgeson\\anaconda3\\envs\\rent_growth_project\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MattBorgeson\\anaconda3\\envs\\rent_growth_project\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MattBorgeson\\anaconda3\\envs\\rent_growth_project\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MattBorgeson\\anaconda3\\envs\\rent_growth_project\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MattBorgeson\\anaconda3\\envs\\rent_growth_project\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\MattBorgeson\\anaconda3\\envs\\rent_growth_project\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-10 15:00:47,838] A new study created in memory with name: no-name-ab38c574-29fc-47bc-b4da-d04627e4f324\n",
      "[I 2025-01-10 15:00:52,300] Trial 8 finished with value: 0.16790402308106422 and parameters: {'lstm_units': 56, 'learning_rate': 5.497147834321914e-05, 'batch_size': 128}. Best is trial 8 with value: 0.16790402308106422.\n",
      "[I 2025-01-10 15:00:53,450] Trial 3 finished with value: 0.03549326557840686 and parameters: {'lstm_units': 78, 'learning_rate': 0.0007223325776677348, 'batch_size': 16}. Best is trial 3 with value: 0.03549326557840686.\n",
      "[I 2025-01-10 15:00:53,581] Trial 2 finished with value: 0.2127694271504879 and parameters: {'lstm_units': 103, 'learning_rate': 1.896228465762261e-05, 'batch_size': 64}. Best is trial 3 with value: 0.03549326557840686.\n",
      "[I 2025-01-10 15:00:53,926] Trial 1 finished with value: 0.1020197669044137 and parameters: {'lstm_units': 78, 'learning_rate': 2.543401897972907e-05, 'batch_size': 16}. Best is trial 3 with value: 0.03549326557840686.\n",
      "[I 2025-01-10 15:00:55,546] Trial 7 finished with value: 0.09960506185889244 and parameters: {'lstm_units': 67, 'learning_rate': 8.534026126167392e-05, 'batch_size': 128}. Best is trial 3 with value: 0.03549326557840686.\n",
      "[I 2025-01-10 15:00:56,634] Trial 4 finished with value: 0.044816536665894094 and parameters: {'lstm_units': 101, 'learning_rate': 0.00042088565757161166, 'batch_size': 64}. Best is trial 3 with value: 0.03549326557840686.\n",
      "[I 2025-01-10 15:00:57,018] Trial 5 finished with value: 0.12205317690968513 and parameters: {'lstm_units': 48, 'learning_rate': 6.26748028681029e-05, 'batch_size': 16}. Best is trial 3 with value: 0.03549326557840686.\n",
      "[I 2025-01-10 15:00:57,753] Trial 0 finished with value: 0.03501380495144986 and parameters: {'lstm_units': 87, 'learning_rate': 0.0011241513871200757, 'batch_size': 32}. Best is trial 0 with value: 0.03501380495144986.\n",
      "[I 2025-01-10 15:00:58,342] Trial 9 finished with value: 0.1540935811586678 and parameters: {'lstm_units': 119, 'learning_rate': 1.772690016903062e-05, 'batch_size': 32}. Best is trial 0 with value: 0.03501380495144986.\n",
      "[I 2025-01-10 15:00:59,328] Trial 6 finished with value: 0.031695650093024594 and parameters: {'lstm_units': 99, 'learning_rate': 0.0006485148482193392, 'batch_size': 16}. Best is trial 6 with value: 0.031695650093024594.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparams: {'lstm_units': 99, 'learning_rate': 0.0006485148482193392, 'batch_size': 16}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTMTimeSeriesModel(\n",
       "  (lstm1): LSTM(21, 99, batch_first=True)\n",
       "  (lstm2): LSTM(99, 99, batch_first=True)\n",
       "  (fc): Linear(in_features=99, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast Type -- Vector Autoregression Analysis\n",
      "Forecast Tools -- Statsmodels\n",
      "VAR Forecast:\n",
      "0    0\n",
      "1    0\n",
      "2   -0\n",
      "3   -0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8   -0\n",
      "9   -0\n",
      "Name: Vector Autoregression (VAR) Forecast, dtype: float64\n",
      "Forecast Type -- Autoregressive Integrated Moving Average (ARIMA) Analysis\n",
      "Forecast Tools -- Statsmodels\n",
      "ARIMA Forecast:\n",
      "70   -0\n",
      "71    0\n",
      "72    0\n",
      "73    0\n",
      "74    0\n",
      "75    0\n",
      "76    0\n",
      "77    0\n",
      "78    0\n",
      "79    0\n",
      "Name: ARIMA Forecasted Rent Growth (%), dtype: float64\n",
      "Forecast Type -- Machine Learning/Neural Network Forecasting Using Optimized Independent Variable/Parameter Weights\n",
      "Forecast Tools -- PyTorch & Optuna\n",
      "Machine Learning Optimized Forecast:\n",
      "0   -0\n",
      "1   -0\n",
      "2   -0\n",
      "3   -0\n",
      "4   -0\n",
      "5   -0\n",
      "6   -0\n",
      "7   -0\n",
      "8   -0\n",
      "9   -0\n",
      "Name: Machine Learning Optimized Forecast, dtype: float32\n",
      "Elapsed time: 0.22 minutes\n"
     ]
    }
   ],
   "source": [
    "#########################################################################################################\n",
    "################################# ALL STATISTICAL CODE IN A SINGLE CELL #################################\n",
    "#########################################################################################################\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the dataset\n",
    "merged_data_file_path = os.path.abspath(f'{fred_data_directory}\\\\Rent Growth Forecast (Quarterly) - Merged Data (Fred Series Data & Phoenix Market Data).xlsx')\n",
    "merged_data = pd.read_excel(merged_data_file_path)\n",
    "merged_data.dropna(inplace=True)\n",
    "\n",
    "# Handle missing values with forward fill\n",
    "df_filled = merged_data.fillna(method='ffill')\n",
    "\n",
    "\n",
    "#################################### Add interaction terms ####################################\n",
    "##### Interaction Type - Multiplication\n",
    "df_filled['Job-Population Interaction'] = df_filled['Job Growth (%)'] * df_filled['Population Growth (%)']\n",
    "df_filled['Income-Population Interaction'] = df_filled['Median Household Income Growth (%)'] * df_filled['Population Growth (%)']\n",
    "df_filled['Job-Income Interaction'] = df_filled['Job Growth (%)'] * df_filled['Median Household Income Growth (%)']\n",
    "df_filled['Job-Under Construction Interaction'] = df_filled['Job Growth (%)'] * df_filled['Under Construction (% of Inventory)']\n",
    "df_filled['Population-Under Construction Interaction'] = df_filled['Population Growth (%)'] * df_filled['Under Construction (% of Inventory)']\n",
    "\n",
    "##### Interaction Type - Division\n",
    "# df_filled['Absorption-Deliveries Interaction'] = df_filled['Absorption - Prior 12 Months (# Units)'] / df_filled['Net Deliveries - Prior 12 Months (# Units)']\n",
    "df_filled['Absorption-Deliveries Interaction'] = df_filled['Quarterly Net Absorption (# Units)'] / df_filled['Quarterly Net Deliveries (# Units)']\n",
    "\n",
    "df_filled['Under Construction-Inventory Interaction'] = df_filled['Under Construction (# Units)'] / df_filled['Inventory (# Units)']\n",
    "# df_filled['Deliveries-Inventory Interaction'] = df_filled['Net Deliveries - Prior 12 Months (# Units)'] / df_filled['Inventory (# Units)']\n",
    "df_filled['Deliveries-Inventory Interaction'] = df_filled['Quarterly Net Deliveries (# Units)'] / df_filled['Inventory (# Units)']\n",
    "\n",
    "df_filled['Occupancy-Inventory Interaction'] = df_filled['Total Occupancy (# Units)'] / df_filled['Inventory (# Units)']\n",
    "df_filled['Vacancy-Inventory Interaction'] = df_filled['Total Vacancy (# Units)'] / df_filled['Inventory (# Units)']\n",
    "df_filled['Unemployed-Labor Force Interaction'] = df_filled['Unemployed Persons in Phoenix-Mesa-Scottsdale, AZ (MSA)'] / df_filled['Civilian Labor Force in Phoenix-Mesa-Scottsdale, AZ (MSA)']\n",
    "df_filled['Employed-Labor Force Interaction'] = df_filled['Employed Persons in Phoenix-Mesa-Scottsdale, AZ (MSA)'] / df_filled['Civilian Labor Force in Phoenix-Mesa-Scottsdale, AZ (MSA)']\n",
    "\n",
    "\n",
    "# Add lagged variables for independent variables\n",
    "df_filled['Unemployment Rate Lagged'] = df_filled['Unemployment Rate (%)'].shift(1)\n",
    "df_filled['Job Growth Lagged'] = df_filled['Job Growth (%)'].shift(1)\n",
    "df_filled['Population Growth Lagged'] = df_filled['Population Growth (%)'].shift(1)\n",
    "\n",
    "# df_filled['Unemployment Rate Lagged'] = df_filled['Unemployment Rate (%)'].shift(4)\n",
    "# df_filled['Job Growth Lagged'] = df_filled['Job Growth (%)'].shift(4)\n",
    "# df_filled['Population Growth Lagged'] = df_filled['Population Growth (%)'].shift(4)\n",
    "\n",
    "\n",
    "# Drop rows with NaN values caused by lagging\n",
    "df_filled = df_filled.dropna()\n",
    "\n",
    "# Define independent and dependent variables\n",
    "X = df_filled[[\n",
    "    'Job-Population Interaction',\n",
    "    'Income-Population Interaction',\n",
    "    'Job-Income Interaction',\n",
    "    'Job-Under Construction Interaction',\n",
    "    'Population-Under Construction Interaction',\n",
    "\n",
    "    'Absorption-Deliveries Interaction',\n",
    "    'Under Construction-Inventory Interaction',\n",
    "    'Deliveries-Inventory Interaction',\n",
    "\n",
    "    'Occupancy-Inventory Interaction',\n",
    "    'Vacancy-Inventory Interaction',\n",
    "    'Unemployed-Labor Force Interaction',\n",
    "    'Employed-Labor Force Interaction',\n",
    "\n",
    "    # 'Quarterly Rent Growth (%) - Lagged',\n",
    "    'Unemployment Rate Lagged',\n",
    "    'Job Growth Lagged',\n",
    "    'Population Growth Lagged',\n",
    "\n",
    "    # 'Inventory (# Units)',\n",
    "    # 'Under Construction (# Units)',\n",
    "    'Under Construction (% of Inventory)',\n",
    "    # 'Absorption - Prior 12 Months (# Units)', \n",
    "    'Quarterly Net Absorption (# Units)',\n",
    "    # 'Net Deliveries - Prior 12 Months (# Units)',\n",
    "    'Quarterly Net Deliveries (# Units)',\n",
    "\n",
    "    # 'Unemployment Rate (%)',\n",
    "    # 'Job Growth (%)',\n",
    "    # 'Population (#)',\n",
    "    # 'Population Growth (%)', \n",
    "    'Median Household Income ($)',\n",
    "    'Median Household Income Growth (%)',\n",
    "               ]]\n",
    "\n",
    "y = df_filled['Quarterly Rent Growth (%)']\n",
    "\n",
    "# Add constant for the regression intercept\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "\n",
    "\n",
    "##################################################################\n",
    "# ------------------ 1. Out-of-Sample Testing ------------------ #\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Ridge regression with cross-validation hyperparameter tuning\n",
    "ridge_params = {'alpha': [0.01, 0.1, 1.0, 10, 100]}\n",
    "ridge_model = Ridge()\n",
    "ridge_cv = GridSearchCV(ridge_model, ridge_params, cv=TimeSeriesSplit(n_splits=5), scoring='r2')\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "# Best model from cross-validation\n",
    "ridge_best = ridge_cv.best_estimator_\n",
    "\n",
    "# Predictions on test set\n",
    "ridge_predictions_train = ridge_best.predict(X_train)\n",
    "ridge_predictions_test = ridge_best.predict(X_test)\n",
    "\n",
    "# Ridge model performance\n",
    "train_r2 = r2_score(y_train, ridge_predictions_train)\n",
    "test_r2 = r2_score(y_test, ridge_predictions_test)\n",
    "\n",
    "# Residual analysis\n",
    "residuals = y_test - ridge_predictions_test\n",
    "# print(\"Residuals summary:\")\n",
    "# print(residuals.describe())\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# ------------------ 2. Vector Autoregression (VAR) ------------------ #\n",
    "# Create VAR model using key time series\n",
    "df_var = df_filled[[\n",
    "    'Quarterly Rent Growth (%)',\n",
    "\n",
    "    'Job-Population Interaction',\n",
    "    'Income-Population Interaction',\n",
    "    'Job-Income Interaction',\n",
    "    'Job-Under Construction Interaction',\n",
    "    'Population-Under Construction Interaction',\n",
    "\n",
    "    'Absorption-Deliveries Interaction',\n",
    "    'Under Construction-Inventory Interaction',\n",
    "    'Deliveries-Inventory Interaction',\n",
    "\n",
    "    'Occupancy-Inventory Interaction',\n",
    "    'Vacancy-Inventory Interaction',\n",
    "    'Unemployed-Labor Force Interaction',\n",
    "    'Employed-Labor Force Interaction',\n",
    "\n",
    "    'Unemployment Rate Lagged',\n",
    "    'Job Growth Lagged',\n",
    "    'Population Growth Lagged',\n",
    "\n",
    "    'Under Construction (% of Inventory)',\n",
    "\n",
    "    # 'Absorption - Prior 12 Months (# Units)', \n",
    "    'Quarterly Net Absorption (# Units)',\n",
    "    # 'Net Deliveries - Prior 12 Months (# Units)',\n",
    "    'Quarterly Net Deliveries (# Units)',\n",
    "\n",
    "    'Unemployment Rate (%)',\n",
    "    'Job Growth (%)',\n",
    "    'Population Growth (%)', \n",
    "    'Median Household Income Growth (%)',\n",
    "    ]]\n",
    "model_var = VAR(df_var)\n",
    "var_results = model_var.fit(maxlags=2)\n",
    "\n",
    "# Forecast periods using VAR\n",
    "# var_forecast_periods = 5\n",
    "var_forecast_periods = 10\n",
    "# var_forecast_periods = 20\n",
    "\n",
    "var_forecast = var_results.forecast(df_var.values[-var_results.k_ar:], steps=var_forecast_periods)\n",
    "var_forecast_df = pd.DataFrame(var_forecast, columns=df_var.columns)\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "# ------------------ 3. ARIMA Time Series Forecasting ------------------ #\n",
    "# Differencing to make the data stationary\n",
    "df_filled['Quarterly Rent Growth Diff'] = df_filled['Quarterly Rent Growth (%)'].diff().dropna()\n",
    "\n",
    "# ARIMA model (order based on dataset properties, p=1, d=1, q=1 as an example)\n",
    "arima_model = ARIMA(df_filled['Quarterly Rent Growth (%)'].dropna(), order=(1, 1, 1))\n",
    "arima_results = arima_model.fit()\n",
    "\n",
    "# future_periods = 5\n",
    "future_periods = 10\n",
    "# future_periods = 20\n",
    "\n",
    "arima_forecast = arima_results.forecast(steps=future_periods)\n",
    "\n",
    "\n",
    "# Create future dates for the forecast\n",
    "last_dataset_date = df_filled['Analysis Date'].max()\n",
    "first_future_date = pd._libs.tslibs.timestamps.Timestamp(year=last_dataset_date.year, month=last_dataset_date.month + 1, day=last_dataset_date.day)\n",
    "\n",
    "future_dates = pd.date_range(start=first_future_date, periods=future_periods, freq='QE', inclusive='right')\n",
    "\n",
    "\n",
    "# Combine future dates and ARIMA forecast values\n",
    "arima_forecast_df = pd.DataFrame({\n",
    "    'Forecasted Date': future_dates,\n",
    "    'ARIMA Forecasted Rent Growth (%)': arima_forecast\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################################################\n",
    "# ------------------ 4. Random Forest (Ensemble Method) ------------------ #\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Random forest performance\n",
    "rf_r2 = r2_score(y_test, rf_predictions)\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# ------------------ 5. LSTM Neural Network for Time Series ------------------ #\n",
    "\n",
    "# Set environment variables for threads (similar idea to TensorFlow's environment vars)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"  # Controls OpenMP threads\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"4\"  # For MKL (if used internally)\n",
    "\n",
    "# Then in your Python code:\n",
    "torch.set_num_threads(4)  # Ensures PyTorch uses 2 threads internally\n",
    "\n",
    "\n",
    "# Create a custom pytorch dataset and retun a dataloader\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch dataset for creating sequences of length `time_steps`\n",
    "    from a 2D feature array X and 1D array y.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, time_steps):\n",
    "        \"\"\"\n",
    "        X: numpy array of shape [num_samples, num_features]\n",
    "        y: numpy array of shape [num_samples]\n",
    "        time_steps: int, number of past timesteps to include in each sample\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.time_steps = time_steps\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of valid sequences = total samples - time_steps\n",
    "        return len(self.X) - self.time_steps\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Sequences range from idx to idx + time_steps\n",
    "        x_seq = self.X[idx : idx + self.time_steps]\n",
    "        y_label = self.y[idx + self.time_steps]  # label at the end of the window\n",
    "        # Convert to float32 tensors\n",
    "        x_seq = torch.tensor(x_seq, dtype=torch.float32)\n",
    "        y_label = torch.tensor(y_label, dtype=torch.float32)\n",
    "        return x_seq, y_label\n",
    "\n",
    "\n",
    "def create_torch_dataloader(X, y, time_steps, batch_size):\n",
    "    \"\"\"\n",
    "    Create a PyTorch DataLoader for time series data.\n",
    "    \"\"\"\n",
    "    dataset = TimeSeriesDataset(X, y, time_steps)\n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False,   # Typically don't shuffle time series\n",
    "        drop_last=False  # Keep all samples\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "# Scaling Data\n",
    "# Example: X, y are your original time series data\n",
    "# They can be NumPy arrays or Pandas DataFrame/Series.\n",
    "\n",
    "scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)  # shape: [samples, features]\n",
    "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMTimeSeriesModel(nn.Module):\n",
    "    def __init__(self, input_dim, lstm_units):\n",
    "        \"\"\"\n",
    "        input_dim : number of features per timestep\n",
    "        lstm_units: hidden dimension (number of LSTM units)\n",
    "        \"\"\"\n",
    "        super(LSTMTimeSeriesModel, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=input_dim, hidden_size=lstm_units, batch_first=True, dropout=0.0)\n",
    "        self.lstm2 = nn.LSTM(input_size=lstm_units, hidden_size=lstm_units, batch_first=True, dropout=0.0)\n",
    "        self.fc = nn.Linear(lstm_units, 1)  # Final dense layer -> 1 output\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, time_steps, input_dim]\n",
    "        out, (h, c) = self.lstm1(x)  # out shape: [batch_size, time_steps, lstm_units]\n",
    "        out, (h, c) = self.lstm2(out)  # out shape: [batch_size, time_steps, lstm_units]\n",
    "        # Take the last timestep's output\n",
    "        last_timestep = out[:, -1, :]  # shape: [batch_size, lstm_units]\n",
    "        return self.fc(last_timestep)  # shape: [batch_size, 1]\n",
    "\n",
    "\n",
    "# Train and evaluate the mnodel using the dataloader\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for x_batch, y_batch in dataloader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs.view(-1), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * x_batch.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    eval_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in dataloader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs.view(-1), y_batch)\n",
    "            eval_loss += loss.item() * x_batch.size(0)\n",
    "\n",
    "    eval_loss = eval_loss / len(dataloader.dataset)\n",
    "    return eval_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "# -------- 6. Forecasting/Prediction with the Best Hyperparameters -------- #\n",
    "# Forecasting\n",
    "time_steps = 10\n",
    "num_epochs = 50\n",
    "\n",
    "\n",
    "def run_optuna_study(X_scaled, y_scaled, time_steps, num_epochs, n_splits=5, n_trials=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    def objective(trial):\n",
    "        # lstm_units = trial.suggest_int('lstm_units', 16, 64)\n",
    "        lstm_units = trial.suggest_int('lstm_units', 16, 128)        \n",
    "\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "\n",
    "        # batch_size = trial.suggest_categorical('batch_size', [16, 32])\n",
    "        batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
    "\n",
    "        avg_loss = 0.0\n",
    "        fold_count = 0\n",
    "\n",
    "        for train_idx, test_idx in tscv.split(X_scaled):\n",
    "            # Split data\n",
    "            X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "            y_train, y_test = y_scaled[train_idx], y_scaled[test_idx]\n",
    "            \n",
    "            # Create Dataloaders\n",
    "            train_loader = create_torch_dataloader(X_train, y_train, time_steps, batch_size)\n",
    "            test_loader  = create_torch_dataloader(X_test,  y_test,  time_steps, batch_size)\n",
    "            \n",
    "            # Build model\n",
    "            input_dim = X_train.shape[1]\n",
    "            model = LSTMTimeSeriesModel(input_dim=input_dim, lstm_units=lstm_units).to(device)\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "            \n",
    "            # Train model for num_epochs\n",
    "            for epoch in range(num_epochs):\n",
    "                train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            test_loss = evaluate(model, test_loader, criterion, device)\n",
    "            avg_loss += test_loss\n",
    "            fold_count += 1\n",
    "        \n",
    "        return avg_loss / fold_count\n",
    "\n",
    "    # Create and run the study\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=n_trials, n_jobs=-1)  # Parallel or single-thread\n",
    "\n",
    "    return study.best_params\n",
    "\n",
    "\n",
    "best_hyperparameters = run_optuna_study(X_scaled, y_scaled, time_steps, num_epochs, n_splits=5, n_trials=10)\n",
    "print(\"Best Hyperparams:\", best_hyperparameters)\n",
    "\n",
    "\n",
    "# Train the model using the best hyperparameters\n",
    "# Suppose you got these from `best_hyperparameters`\n",
    "num_lstm_units = best_hyperparameters['lstm_units']\n",
    "learning_rate  = best_hyperparameters['learning_rate']\n",
    "batch_size     = best_hyperparameters['batch_size']\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create a single DataLoader over the entire dataset\n",
    "full_loader = create_torch_dataloader(X_scaled, y_scaled, time_steps, batch_size)\n",
    "\n",
    "model_lstm = LSTMTimeSeriesModel(\n",
    "    input_dim=X_scaled.shape[1], \n",
    "    lstm_units=num_lstm_units\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model_lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "# num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch(model_lstm, full_loader, criterion, optimizer, device)\n",
    "    # If desired, implement an early stopping check here\n",
    "    # ...\n",
    "    # print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.6f}\")\n",
    "\n",
    "# Optionally save your final model weights\n",
    "checkpoint_filepath = os.path.abspath(r\"C:\\Users\\MattBorgeson\\OneDrive - B&R Capital\\Programming Projects\\Rent Growth Forecasting\\Output Files\\Best Model Weights/best_model_fold_torch (Quarterly).pt\")\n",
    "# checkpoint_filepath = os.path.abspath(\"best_model_fold_torch.pt\")\n",
    "torch.save(model_lstm.state_dict(), checkpoint_filepath)\n",
    "\n",
    "# To load them later:\n",
    "# model_lstm.load_state_dict(torch.load(checkpoint_filepath))\n",
    "# model_lstm.eval()\n",
    "\n",
    "\n",
    "# Autoregressive Forecasting with LSTM\n",
    "model_lstm.eval()\n",
    "\n",
    "last_sequence = X_scaled[-time_steps:].copy()  # shape: (time_steps, num_features)\n",
    "ml_optimized_predictions = []\n",
    "\n",
    "\n",
    "forecast_num_steps = 10  # e.g., 10 future steps\n",
    "for _ in range(forecast_num_steps):\n",
    "    # (1) Reshape for model: [batch_size=1, time_steps, num_features]\n",
    "    seq_input = torch.tensor(last_sequence, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    \n",
    "    # (2) Predict\n",
    "    with torch.no_grad():\n",
    "        next_value_scaled_tensor = model_lstm(seq_input)  # shape: [1, 1]\n",
    "    \n",
    "    next_value_scaled = next_value_scaled_tensor.cpu().numpy().reshape(-1, 1)\n",
    "    \n",
    "    # (3) Inverse transform from scaled to original\n",
    "    next_value_original_scale = scaler_y.inverse_transform(next_value_scaled)\n",
    "    ml_optimized_predictions.append(next_value_original_scale[0, 0])\n",
    "    \n",
    "    # (4) Update the last_sequence with this new predicted value\n",
    "    #     If your target is the 1st column, place it there:\n",
    "    next_features = np.zeros((1, last_sequence.shape[1]))\n",
    "    next_value_rescaled = scaler_y.transform(next_value_original_scale)  # scale back for model continuity\n",
    "    next_features[0, 0] = next_value_rescaled[0, 0]\n",
    "    \n",
    "    # Shift and append\n",
    "    last_sequence = np.vstack([last_sequence[1:], next_features])\n",
    "\n",
    "ml_optimized_forecast_df = arima_forecast_df.copy(deep=True)\n",
    "ml_optimized_forecast_df[\"Machine Learning Optimized Forecast\"] = ml_optimized_predictions\n",
    "ml_optimized_forecast_df.drop(columns=['ARIMA Forecasted Rent Growth (%)'], inplace=True, errors='ignore')\n",
    "ml_optimized_forecast_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############################################################\n",
    "# ------------------ 7. Summary & Outputs ------------------ #\n",
    "rent_growth_forecasts_df = arima_forecast_df.copy(deep=True)\n",
    "rent_growth_forecasts_df[\"Machine Learning Optimized Forecast\"] = list(ml_optimized_forecast_df[\"Machine Learning Optimized Forecast\"])\n",
    "rent_growth_forecasts_df['Vector Autoregression (VAR) Forecast'] = list(var_forecast_df['Quarterly Rent Growth (%)'])\n",
    "rent_growth_forecasts_df.rename(columns={'ARIMA Forecasted Rent Growth (%)':'ARIMA Forecast'}, inplace=True)\n",
    "\n",
    "\n",
    "# print(f\"Ridge Regression R^2 on Train: {train_r2}, Test: {test_r2}\")\n",
    "# print(f\"Random Forest R^2 on Test: {rf_r2}\")\n",
    "\n",
    "\n",
    "var_forecast_df.rename(columns={'Quarterly Rent Growth (%)':'Vector Autoregression (VAR) Forecast'}, inplace=True)\n",
    "print(\"Forecast Type -- Vector Autoregression Analysis\")\n",
    "print(\"Forecast Tools -- Statsmodels\")\n",
    "print(f\"VAR Forecast:\")\n",
    "print(var_forecast_df['Vector Autoregression (VAR) Forecast'])\n",
    "\n",
    "\n",
    "print(\"Forecast Type -- Autoregressive Integrated Moving Average (ARIMA) Analysis\")\n",
    "print(\"Forecast Tools -- Statsmodels\")\n",
    "print(f\"ARIMA Forecast:\")\n",
    "print(arima_forecast_df['ARIMA Forecasted Rent Growth (%)'])\n",
    "\n",
    "\n",
    "print(\"Forecast Type -- Machine Learning/Neural Network Forecasting Using Optimized Independent Variable/Parameter Weights\")\n",
    "print(\"Forecast Tools -- PyTorch & Optuna\")\n",
    "# print(f\"Forecasted values for the next {forecast_num_steps} time steps:\")\n",
    "print(f\"Machine Learning Optimized Forecast:\")\n",
    "print(ml_optimized_forecast_df[\"Machine Learning Optimized Forecast\"])\n",
    "\n",
    "\n",
    "# Save the Forecasts DataFrame with all forecasts to an Excel file\n",
    "forecasting_analysis_outputs_file_path = os.path.abspath(r'C:\\Users\\MattBorgeson\\OneDrive - B&R Capital\\Programming Projects\\Rent Growth Forecasting\\Output Files\\Forecasts')\n",
    "\n",
    "\n",
    "var_forecast_file_path = os.path.abspath(f'{forecasting_analysis_outputs_file_path}\\\\VAR Forecast Model Forecasts (Quarterly).xlsx')\n",
    "arima_forecast_file_path = os.path.abspath(f'{forecasting_analysis_outputs_file_path}\\\\ARIMA Forecast Model Forecasts (Quarterly).xlsx')\n",
    "ml_optimized_forecast_file_path = os.path.abspath(f'{forecasting_analysis_outputs_file_path}\\\\Machine Learning Forecast Model Forecasts (Quarterly).xlsx')\n",
    "all_forecasts_file_path = os.path.abspath(f'{forecasting_analysis_outputs_file_path}\\\\All Forecast Methodologies Forecasts (Quarterly).xlsx')\n",
    "\n",
    "\n",
    "# var_forecast_df.to_excel(var_forecast_file_path, index=False)\n",
    "# arima_forecast_df.to_excel(arima_forecast_file_path, index=False)\n",
    "# ml_optimized_forecast_df.to_excel(ml_optimized_forecast_file_path, index=False)\n",
    "rent_growth_forecasts_df.to_excel(all_forecasts_file_path, index=False)\n",
    "\n",
    "\n",
    "\n",
    "##############################################################\n",
    "# -------------------- 8. Code Run Time -------------------- #\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "elapsed_time = (elapsed_time/60)\n",
    "elapsed_time = round(elapsed_time, 2)\n",
    "print(f\"Elapsed time: {elapsed_time} minutes\")\n",
    "\n",
    "def code_completion_notification ():\n",
    "    engine = pyttsx3.init()\n",
    "    # engine.endLoop()    \n",
    "    \n",
    "    try:\n",
    "        engine.endLoop()\n",
    "        del engine\n",
    "        engine = pyttsx3.init()\n",
    "    except:\n",
    "        pass\n",
    "        code_run_time = f\"The code took {elapsed_time} minutes to run.\"\n",
    "        text = \"Quarterly Rent Growth Forecast Analysis Complete.\"\n",
    "        text = f\"{text} {code_run_time}\"\n",
    "\n",
    "        engine.setProperty('rate', 225)\n",
    "\n",
    "        volume = engine.getProperty('volume')\n",
    "        engine.setProperty('volume', volume+0.50)\n",
    "\n",
    "        winsound.Beep(750, 1250)\n",
    "        engine.say(text)\n",
    "\n",
    "        engine.startLoop(False)\n",
    "        engine.iterate()\n",
    "        engine.endLoop()        \n",
    "\n",
    "\n",
    "code_completion_notification ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.A.3) RENT GROWTH FORECASTING -- ANNUAL RENT GROWTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.A.3.1) READING SELECTED EXCEL SHEETS INTO A MERGED DATAFRAME (ANNUAL RENT GROWTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################\n",
    "#################################### CREATE THE MERGED DATAFRAME & EXPORT TO EXCEL ####################################\n",
    "#######################################################################################################################\n",
    "market_analysis_df = pd.read_excel(market_analysis_file_path)\n",
    "fred_data_df = pd.read_excel(fred_data_file_path)\n",
    "\n",
    "\n",
    "merged_data_df = pd.merge(market_analysis_df, fred_data_df, left_on=\"Analysis Date\", right_on=\"Adjusted Analysis Date\", how='inner')\n",
    "merged_data_df.rename(columns={\"Analysis Date_x\":\"Analysis Date\"}, inplace=True)\n",
    "merged_data_df.rename(columns={\"Adjusted Analysis Day\":\"Analysis Day\"}, inplace=True)\n",
    "\n",
    "\n",
    "# analysis_day_col = merged_data_df.pop(\"Analysis Day\")\n",
    "# merged_data_df.insert(3, \"Analysis Day\", analysis_day_col)\n",
    "\n",
    "# merged_data_col_drop_list = [\n",
    "#     \"Analysis Date_y\",\n",
    "#     \"Adjusted Analysis Date\",\n",
    "#     \"Adjusted Analysis Year\",\n",
    "#     \"Adjusted Analysis Month\",\n",
    "#     \"Analysis Year\",\n",
    "#     \"Analysis Month\",\n",
    "#     \"Analysis Day\",\n",
    "#     \"Annual Rent Growth (%)\",\n",
    "#     \"Annual Rent Growth (%) - Lagged\",\n",
    "#     \"Stabilized Vacancy (%)\",\n",
    "#     \"Market Asking Rent/Unit ($)\",\n",
    "# ]\n",
    "\n",
    "# merged_data_df.drop(columns=merged_data_col_drop_list, inplace=True)\n",
    "# merged_data_df\n",
    "\n",
    "\n",
    "\n",
    "merged_data_col_list = [\n",
    "    \"Analysis Date\",\n",
    "    \"Market Name\",\n",
    "\n",
    "    \"Annual Rent Growth (%)\",\n",
    "    # \"Annual Rent Growth (%) - Lagged\",\n",
    "    # \"Quarterly Rent Growth (%)\",\n",
    "    # \"Quarterly Rent Growth (%) - Lagged\",\n",
    "\n",
    "    \"Inventory (# Units)\",\n",
    "    \"Under Construction (# Units)\",\n",
    "    \"Under Construction (% of Inventory)\",\n",
    "    \"Total Occupancy (# Units)\",\n",
    "    \"Total Vacancy (# Units)\",\n",
    "\n",
    "    \"Quarterly Net Deliveries (# Units)\",\n",
    "    \"Quarterly Construction Starts (# Units)\",\n",
    "    \"Quarterly Net Absorption (# Units)\",\n",
    "    \"Absorption - Prior 12 Months (# Units)\",\n",
    "    \"Net Deliveries - Prior 12 Months (# Units)\",\n",
    "\n",
    "    \"Unemployment Rate (%)\",\n",
    "    \"Job Growth (%)\",\n",
    "    \"Population (#)\",\n",
    "    \"Population Growth (%)\",\n",
    "    \"Median Household Income ($)\",\n",
    "    \"Median Household Income Growth (%)\",\n",
    "\n",
    "    \"Federal Funds Effective Rate\",\n",
    "\n",
    "    \"Consumer Price Index for All Urban Consumers: All Items in U.S. City Average\",\n",
    "\n",
    "    \"Unemployed Persons in Phoenix-Mesa-Scottsdale, AZ (MSA)\",\n",
    "    \"Employed Persons in Phoenix-Mesa-Scottsdale, AZ (MSA)\",\n",
    "    \"Civilian Labor Force in Phoenix-Mesa-Scottsdale, AZ (MSA)\",\n",
    "    \"Unemployment Rate in Phoenix-Mesa-Scottsdale, AZ (MSA)\",\n",
    "\n",
    "    \"S&P CoreLogic Case-Shiller AZ-Phoenix Home Price Index\",\n",
    "]\n",
    "\n",
    "\n",
    "annual_forecast_merged_data_df = merged_data_df[merged_data_col_list]\n",
    "\n",
    "annual_forecast_merged_data_df = annual_forecast_merged_data_df[annual_forecast_merged_data_df != '-']\n",
    "annual_forecast_merged_data_df[\"Annual Rent Growth (%)\"] = annual_forecast_merged_data_df[\"Annual Rent Growth (%)\"].astype('float')\n",
    "annual_forecast_merged_data_df.dropna(inplace=True)\n",
    "annual_forecast_merged_data_df.reset_index(inplace=True)\n",
    "annual_forecast_merged_data_df.drop(columns=['index'], inplace=True)\n",
    "\n",
    "\n",
    "############ Export the merged Dataframe to Excel\n",
    "annual_forecast_merged_data_file_path = os.path.abspath(f'{fred_data_directory}\\\\Rent Growth Forecast (Annual) - Merged Data (Fred Series Data & Phoenix Market Data).xlsx')\n",
    "annual_forecast_merged_data_df.to_excel(annual_forecast_merged_data_file_path, index=False)\n",
    "\n",
    "merged_data_df = merged_data_df[merged_data_col_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.A.3.2) MULTIVARIATE TIME SERIES ANALYSIS (ANNUAL RENT GROWTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MattBorgeson\\AppData\\Local\\Temp\\ipykernel_52940\\4248759407.py:13: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_filled = merged_data.fillna(method='ffill')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "             estimator=Ridge(), param_grid={&#x27;alpha&#x27;: [0.01, 0.1, 1.0, 10, 100]},\n",
       "             scoring=&#x27;r2&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "             estimator=Ridge(), param_grid={&#x27;alpha&#x27;: [0.01, 0.1, 1.0, 10, 100]},\n",
       "             scoring=&#x27;r2&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: Ridge</label><div class=\"sk-toggleable__content fitted\"><pre>Ridge(alpha=0.01)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;Ridge<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.Ridge.html\">?<span>Documentation for Ridge</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>Ridge(alpha=0.01)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "             estimator=Ridge(), param_grid={'alpha': [0.01, 0.1, 1.0, 10, 100]},\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MattBorgeson\\anaconda3\\envs\\rent_growth_project\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MattBorgeson\\anaconda3\\envs\\rent_growth_project\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MattBorgeson\\anaconda3\\envs\\rent_growth_project\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MattBorgeson\\anaconda3\\envs\\rent_growth_project\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\MattBorgeson\\anaconda3\\envs\\rent_growth_project\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\MattBorgeson\\anaconda3\\envs\\rent_growth_project\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-10 15:01:18,976] A new study created in memory with name: no-name-fa9d5102-37b8-48ed-9b8b-acf809cf2934\n",
      "[I 2025-01-10 15:01:21,758] Trial 8 finished with value: 0.3011873383074999 and parameters: {'lstm_units': 91, 'learning_rate': 1.2562786074377366e-05, 'batch_size': 64}. Best is trial 8 with value: 0.3011873383074999.\n",
      "[I 2025-01-10 15:01:24,125] Trial 4 finished with value: 0.10813714842274749 and parameters: {'lstm_units': 121, 'learning_rate': 0.0005714338686633816, 'batch_size': 16}. Best is trial 4 with value: 0.10813714842274749.\n",
      "[I 2025-01-10 15:01:24,850] Trial 9 finished with value: 0.15307782627642155 and parameters: {'lstm_units': 77, 'learning_rate': 6.058098125652396e-05, 'batch_size': 16}. Best is trial 4 with value: 0.10813714842274749.\n",
      "[I 2025-01-10 15:01:24,909] Trial 6 finished with value: 0.11203580247238279 and parameters: {'lstm_units': 122, 'learning_rate': 0.0001895505783311923, 'batch_size': 32}. Best is trial 4 with value: 0.10813714842274749.\n",
      "[I 2025-01-10 15:01:26,105] Trial 7 finished with value: 0.09653594825867913 and parameters: {'lstm_units': 97, 'learning_rate': 0.0010157137427549668, 'batch_size': 32}. Best is trial 7 with value: 0.09653594825867913.\n",
      "[I 2025-01-10 15:01:26,978] Trial 3 finished with value: 0.07408240539371036 and parameters: {'lstm_units': 82, 'learning_rate': 0.0012682446972987571, 'batch_size': 32}. Best is trial 3 with value: 0.07408240539371036.\n",
      "[I 2025-01-10 15:01:27,811] Trial 0 finished with value: 0.32004658807709346 and parameters: {'lstm_units': 30, 'learning_rate': 3.2963159137415806e-05, 'batch_size': 64}. Best is trial 3 with value: 0.07408240539371036.\n",
      "[I 2025-01-10 15:01:28,532] Trial 2 finished with value: 0.1358231246471405 and parameters: {'lstm_units': 67, 'learning_rate': 4.865425985872269e-05, 'batch_size': 16}. Best is trial 3 with value: 0.07408240539371036.\n",
      "[I 2025-01-10 15:01:29,585] Trial 5 finished with value: 0.11178725552163087 and parameters: {'lstm_units': 113, 'learning_rate': 0.0002612629785671231, 'batch_size': 16}. Best is trial 3 with value: 0.07408240539371036.\n",
      "[I 2025-01-10 15:01:30,050] Trial 1 finished with value: 0.07944146435929725 and parameters: {'lstm_units': 82, 'learning_rate': 0.000914419866619417, 'batch_size': 16}. Best is trial 3 with value: 0.07408240539371036.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparams: {'lstm_units': 82, 'learning_rate': 0.0012682446972987571, 'batch_size': 32}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTMTimeSeriesModel(\n",
       "  (lstm1): LSTM(21, 82, batch_first=True)\n",
       "  (lstm2): LSTM(82, 82, batch_first=True)\n",
       "  (fc): Linear(in_features=82, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast Type -- Vector Autoregression Analysis\n",
      "Forecast Tools -- Statsmodels\n",
      "VAR Forecast:\n",
      "0   -0\n",
      "1   -0\n",
      "2   -0\n",
      "3   -0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "9    0\n",
      "Name: Vector Autoregression (VAR) Forecast, dtype: float64\n",
      "Forecast Type -- Autoregressive Integrated Moving Average (ARIMA) Analysis\n",
      "Forecast Tools -- Statsmodels\n",
      "ARIMA Forecast:\n",
      "0   -0\n",
      "1   -0\n",
      "2   -0\n",
      "3   -0\n",
      "4   -0\n",
      "5   -0\n",
      "6   -0\n",
      "7   -0\n",
      "8   -0\n",
      "9   -0\n",
      "Name: ARIMA Forecasted Rent Growth (%), dtype: float64\n",
      "Forecast Type -- Machine Learning/Neural Network Forecasting Using Optimized Independent Variable/Parameter Weights\n",
      "Forecast Tools -- PyTorch & Optuna\n",
      "Machine Learning Optimized Forecast:\n",
      "0   0\n",
      "1   0\n",
      "2   0\n",
      "3   0\n",
      "4   0\n",
      "5   0\n",
      "6   0\n",
      "7   0\n",
      "8   0\n",
      "9   0\n",
      "Name: Machine Learning Optimized Forecast, dtype: float32\n",
      "Elapsed time: 0.2 minutes\n"
     ]
    }
   ],
   "source": [
    "#########################################################################################################\n",
    "################################# ALL STATISTICAL CODE IN A SINGLE CELL #################################\n",
    "#########################################################################################################\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the dataset\n",
    "# merged_data_file_path = os.path.abspath(f'{fred_data_directory}\\\\Rent Growth Forecast (Quarterly) - Merged Data (Fred Series Data & Phoenix Market Data).xlsx')\n",
    "merged_data_file_path = os.path.abspath(f'{fred_data_directory}\\\\Rent Growth Forecast (Annual) - Merged Data (Fred Series Data & Phoenix Market Data).xlsx')\n",
    "merged_data = pd.read_excel(merged_data_file_path)\n",
    "merged_data.dropna(inplace=True)\n",
    "\n",
    "# Handle missing values with forward fill\n",
    "df_filled = merged_data.fillna(method='ffill')\n",
    "\n",
    "\n",
    "#################################### Add interaction terms ####################################\n",
    "##### Interaction Type - Multiplication\n",
    "df_filled['Job-Population Interaction'] = df_filled['Job Growth (%)'] * df_filled['Population Growth (%)']\n",
    "df_filled['Income-Population Interaction'] = df_filled['Median Household Income Growth (%)'] * df_filled['Population Growth (%)']\n",
    "df_filled['Job-Income Interaction'] = df_filled['Job Growth (%)'] * df_filled['Median Household Income Growth (%)']\n",
    "df_filled['Job-Under Construction Interaction'] = df_filled['Job Growth (%)'] * df_filled['Under Construction (% of Inventory)']\n",
    "df_filled['Population-Under Construction Interaction'] = df_filled['Population Growth (%)'] * df_filled['Under Construction (% of Inventory)']\n",
    "\n",
    "##### Interaction Type - Division\n",
    "df_filled['Absorption-Deliveries Interaction'] = df_filled['Absorption - Prior 12 Months (# Units)'] / df_filled['Net Deliveries - Prior 12 Months (# Units)']\n",
    "# df_filled['Absorption-Deliveries Interaction'] = df_filled['Quarterly Net Absorption (# Units)'] / df_filled['Quarterly Net Deliveries (# Units)']\n",
    "\n",
    "df_filled['Under Construction-Inventory Interaction'] = df_filled['Under Construction (# Units)'] / df_filled['Inventory (# Units)']\n",
    "df_filled['Deliveries-Inventory Interaction'] = df_filled['Net Deliveries - Prior 12 Months (# Units)'] / df_filled['Inventory (# Units)']\n",
    "# df_filled['Deliveries-Inventory Interaction'] = df_filled['Quarterly Net Deliveries (# Units)'] / df_filled['Inventory (# Units)']\n",
    "\n",
    "df_filled['Occupancy-Inventory Interaction'] = df_filled['Total Occupancy (# Units)'] / df_filled['Inventory (# Units)']\n",
    "df_filled['Vacancy-Inventory Interaction'] = df_filled['Total Vacancy (# Units)'] / df_filled['Inventory (# Units)']\n",
    "df_filled['Unemployed-Labor Force Interaction'] = df_filled['Unemployed Persons in Phoenix-Mesa-Scottsdale, AZ (MSA)'] / df_filled['Civilian Labor Force in Phoenix-Mesa-Scottsdale, AZ (MSA)']\n",
    "df_filled['Employed-Labor Force Interaction'] = df_filled['Employed Persons in Phoenix-Mesa-Scottsdale, AZ (MSA)'] / df_filled['Civilian Labor Force in Phoenix-Mesa-Scottsdale, AZ (MSA)']\n",
    "\n",
    "\n",
    "# Add lagged variables for independent variables\n",
    "# df_filled['Unemployment Rate Lagged'] = df_filled['Unemployment Rate (%)'].shift(1)\n",
    "# df_filled['Job Growth Lagged'] = df_filled['Job Growth (%)'].shift(1)\n",
    "# df_filled['Population Growth Lagged'] = df_filled['Population Growth (%)'].shift(1)\n",
    "\n",
    "df_filled['Unemployment Rate Lagged'] = df_filled['Unemployment Rate (%)'].shift(4)\n",
    "df_filled['Job Growth Lagged'] = df_filled['Job Growth (%)'].shift(4)\n",
    "df_filled['Population Growth Lagged'] = df_filled['Population Growth (%)'].shift(4)\n",
    "\n",
    "\n",
    "# Drop rows with NaN values caused by lagging\n",
    "df_filled = df_filled.dropna()\n",
    "\n",
    "# Define independent and dependent variables\n",
    "X = df_filled[[\n",
    "    'Job-Population Interaction',\n",
    "    'Income-Population Interaction',\n",
    "    'Job-Income Interaction',\n",
    "    'Job-Under Construction Interaction',\n",
    "    'Population-Under Construction Interaction',\n",
    "\n",
    "    'Absorption-Deliveries Interaction',\n",
    "    'Under Construction-Inventory Interaction',\n",
    "    'Deliveries-Inventory Interaction',\n",
    "\n",
    "    'Occupancy-Inventory Interaction',\n",
    "    'Vacancy-Inventory Interaction',\n",
    "    'Unemployed-Labor Force Interaction',\n",
    "    'Employed-Labor Force Interaction',\n",
    "    \n",
    "    # 'Annual Rent Growth (%) - Lagged',\n",
    "    'Unemployment Rate Lagged',\n",
    "    'Job Growth Lagged',\n",
    "    'Population Growth Lagged',\n",
    "\n",
    "    # 'Inventory (# Units)',\n",
    "    # 'Under Construction (# Units)',\n",
    "    'Under Construction (% of Inventory)',\n",
    "    'Absorption - Prior 12 Months (# Units)', \n",
    "    # 'Quarterly Net Absorption (# Units)',\n",
    "    'Net Deliveries - Prior 12 Months (# Units)',\n",
    "    # 'Quarterly Net Deliveries (# Units)',\n",
    "\n",
    "    # 'Unemployment Rate (%)',\n",
    "    # 'Job Growth (%)',\n",
    "    # 'Population (#)',\n",
    "    # 'Population Growth (%)', \n",
    "    'Median Household Income ($)',\n",
    "    'Median Household Income Growth (%)',\n",
    "               ]]\n",
    "\n",
    "y = df_filled['Annual Rent Growth (%)']\n",
    "\n",
    "# Add constant for the regression intercept\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "\n",
    "\n",
    "##################################################################\n",
    "# ------------------ 1. Out-of-Sample Testing ------------------ #\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Ridge regression with cross-validation hyperparameter tuning\n",
    "ridge_params = {'alpha': [0.01, 0.1, 1.0, 10, 100]}\n",
    "ridge_model = Ridge()\n",
    "ridge_cv = GridSearchCV(ridge_model, ridge_params, cv=TimeSeriesSplit(n_splits=5), scoring='r2')\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "# Best model from cross-validation\n",
    "ridge_best = ridge_cv.best_estimator_\n",
    "\n",
    "# Predictions on test set\n",
    "ridge_predictions_train = ridge_best.predict(X_train)\n",
    "ridge_predictions_test = ridge_best.predict(X_test)\n",
    "\n",
    "# Ridge model performance\n",
    "train_r2 = r2_score(y_train, ridge_predictions_train)\n",
    "test_r2 = r2_score(y_test, ridge_predictions_test)\n",
    "\n",
    "# Residual analysis\n",
    "residuals = y_test - ridge_predictions_test\n",
    "# print(\"Residuals summary:\")\n",
    "# print(residuals.describe())\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# ------------------ 2. Vector Autoregression (VAR) ------------------ #\n",
    "# Create VAR model using key time series\n",
    "df_var = df_filled[[\n",
    "    'Annual Rent Growth (%)',\n",
    "\n",
    "    'Job-Population Interaction',\n",
    "    'Income-Population Interaction',\n",
    "    'Job-Income Interaction',\n",
    "    'Job-Under Construction Interaction',\n",
    "    'Population-Under Construction Interaction',\n",
    "\n",
    "    'Absorption-Deliveries Interaction',\n",
    "    'Under Construction-Inventory Interaction',\n",
    "    'Deliveries-Inventory Interaction',\n",
    "\n",
    "    'Occupancy-Inventory Interaction',\n",
    "    'Vacancy-Inventory Interaction',\n",
    "    'Unemployed-Labor Force Interaction',\n",
    "    'Employed-Labor Force Interaction',\n",
    "\n",
    "    'Unemployment Rate Lagged',\n",
    "    'Job Growth Lagged',\n",
    "    'Population Growth Lagged',\n",
    "\n",
    "    'Under Construction (% of Inventory)',\n",
    "\n",
    "    'Absorption - Prior 12 Months (# Units)', \n",
    "    # 'Quarterly Net Absorption (# Units)',\n",
    "    'Net Deliveries - Prior 12 Months (# Units)',\n",
    "    # 'Quarterly Net Deliveries (# Units)',\n",
    "\n",
    "    'Unemployment Rate (%)',\n",
    "    'Job Growth (%)',\n",
    "    'Population Growth (%)', \n",
    "    'Median Household Income Growth (%)',\n",
    "    ]]\n",
    "model_var = VAR(df_var)\n",
    "var_results = model_var.fit(maxlags=2)\n",
    "\n",
    "# Forecast periods using VAR\n",
    "# var_forecast_periods = 5\n",
    "var_forecast_periods = 10\n",
    "# var_forecast_periods = 20\n",
    "\n",
    "var_forecast = var_results.forecast(df_var.values[-var_results.k_ar:], steps=var_forecast_periods)\n",
    "var_forecast_df = pd.DataFrame(var_forecast, columns=df_var.columns)\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "# ------------------ 3. ARIMA Time Series Forecasting ------------------ #\n",
    "# Differencing to make the data stationary\n",
    "df_filled['Annual Rent Growth Diff'] = df_filled['Annual Rent Growth (%)'].diff().dropna()\n",
    "\n",
    "# ARIMA model (order based on dataset properties, p=1, d=1, q=1 as an example)\n",
    "arima_model = ARIMA(df_filled['Annual Rent Growth (%)'].dropna(), order=(1, 1, 1))\n",
    "arima_results = arima_model.fit()\n",
    "\n",
    "# future_periods = 5\n",
    "future_periods = 10\n",
    "# future_periods = 20\n",
    "\n",
    "arima_forecast = arima_results.forecast(steps=future_periods)\n",
    "\n",
    "\n",
    "# Create future dates for the forecast\n",
    "last_dataset_date = df_filled['Analysis Date'].max()\n",
    "first_future_date = pd._libs.tslibs.timestamps.Timestamp(year=last_dataset_date.year + 1, month=last_dataset_date.month, day=last_dataset_date.day)\n",
    "\n",
    "# future_dates = pd.date_range(start=first_future_date, periods=future_periods, freq='A', inclusive='right')\n",
    "future_dates = pd.date_range(start=first_future_date, periods=future_periods, freq='YE', inclusive='right')\n",
    "\n",
    "\n",
    "# Combine future dates and ARIMA forecast values\n",
    "arima_forecast_df = pd.DataFrame({\n",
    "    'Forecasted Date': future_dates,\n",
    "    'ARIMA Forecasted Rent Growth (%)': arima_forecast\n",
    "})\n",
    "\n",
    "arima_forecast_df.reset_index(inplace=True)\n",
    "arima_forecast_df.drop(columns=[\"index\"], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "############################################################################\n",
    "# ------------------ 4. Random Forest (Ensemble Method) ------------------ #\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Random forest performance\n",
    "rf_r2 = r2_score(y_test, rf_predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# ------------------ 5. LSTM Neural Network for Time Series ------------------ #\n",
    "\n",
    "# Set environment variables for threads (similar idea to TensorFlow's environment vars)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"  # Controls OpenMP threads\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"4\"  # For MKL (if used internally)\n",
    "\n",
    "# Then in your Python code:\n",
    "torch.set_num_threads(4)  # Ensures PyTorch uses 2 threads internally\n",
    "\n",
    "\n",
    "# Create a custom pytorch dataset and retun a dataloader\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch dataset for creating sequences of length `time_steps`\n",
    "    from a 2D feature array X and 1D array y.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, time_steps):\n",
    "        \"\"\"\n",
    "        X: numpy array of shape [num_samples, num_features]\n",
    "        y: numpy array of shape [num_samples]\n",
    "        time_steps: int, number of past timesteps to include in each sample\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.time_steps = time_steps\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of valid sequences = total samples - time_steps\n",
    "        return len(self.X) - self.time_steps\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Sequences range from idx to idx + time_steps\n",
    "        x_seq = self.X[idx : idx + self.time_steps]\n",
    "        y_label = self.y[idx + self.time_steps]  # label at the end of the window\n",
    "        # Convert to float32 tensors\n",
    "        x_seq = torch.tensor(x_seq, dtype=torch.float32)\n",
    "        y_label = torch.tensor(y_label, dtype=torch.float32)\n",
    "        return x_seq, y_label\n",
    "\n",
    "\n",
    "def create_torch_dataloader(X, y, time_steps, batch_size):\n",
    "    \"\"\"\n",
    "    Create a PyTorch DataLoader for time series data.\n",
    "    \"\"\"\n",
    "    dataset = TimeSeriesDataset(X, y, time_steps)\n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False,   # Typically don't shuffle time series\n",
    "        drop_last=False  # Keep all samples\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "# Scaling Data\n",
    "# Example: X, y are your original time series data\n",
    "# They can be NumPy arrays or Pandas DataFrame/Series.\n",
    "\n",
    "scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)  # shape: [samples, features]\n",
    "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMTimeSeriesModel(nn.Module):\n",
    "    def __init__(self, input_dim, lstm_units):\n",
    "        \"\"\"\n",
    "        input_dim : number of features per timestep\n",
    "        lstm_units: hidden dimension (number of LSTM units)\n",
    "        \"\"\"\n",
    "        super(LSTMTimeSeriesModel, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=input_dim, hidden_size=lstm_units, batch_first=True, dropout=0.0)\n",
    "        self.lstm2 = nn.LSTM(input_size=lstm_units, hidden_size=lstm_units, batch_first=True, dropout=0.0)\n",
    "        self.fc = nn.Linear(lstm_units, 1)  # Final dense layer -> 1 output\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, time_steps, input_dim]\n",
    "        out, (h, c) = self.lstm1(x)  # out shape: [batch_size, time_steps, lstm_units]\n",
    "        out, (h, c) = self.lstm2(out)  # out shape: [batch_size, time_steps, lstm_units]\n",
    "        # Take the last timestep's output\n",
    "        last_timestep = out[:, -1, :]  # shape: [batch_size, lstm_units]\n",
    "        return self.fc(last_timestep)  # shape: [batch_size, 1]\n",
    "\n",
    "\n",
    "# Train and evaluate the mnodel using the dataloader\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for x_batch, y_batch in dataloader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs.view(-1), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * x_batch.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    eval_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in dataloader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs.view(-1), y_batch)\n",
    "            eval_loss += loss.item() * x_batch.size(0)\n",
    "\n",
    "    eval_loss = eval_loss / len(dataloader.dataset)\n",
    "    return eval_loss\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "# -------- 6. Forecasting/Prediction with the Best Hyperparameters -------- #\n",
    "# Forecasting\n",
    "time_steps = 10\n",
    "num_epochs = 50\n",
    "\n",
    "\n",
    "def run_optuna_study(X_scaled, y_scaled, time_steps, num_epochs, n_splits=5, n_trials=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    def objective(trial):\n",
    "        # lstm_units = trial.suggest_int('lstm_units', 16, 64)\n",
    "        lstm_units = trial.suggest_int('lstm_units', 16, 128)        \n",
    "\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "\n",
    "        # batch_size = trial.suggest_categorical('batch_size', [16, 32])\n",
    "        batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
    "\n",
    "        avg_loss = 0.0\n",
    "        fold_count = 0\n",
    "\n",
    "        for train_idx, test_idx in tscv.split(X_scaled):\n",
    "            # Split data\n",
    "            X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "            y_train, y_test = y_scaled[train_idx], y_scaled[test_idx]\n",
    "            \n",
    "            # Create Dataloaders\n",
    "            train_loader = create_torch_dataloader(X_train, y_train, time_steps, batch_size)\n",
    "            test_loader  = create_torch_dataloader(X_test,  y_test,  time_steps, batch_size)\n",
    "            \n",
    "            # Build model\n",
    "            input_dim = X_train.shape[1]\n",
    "            model = LSTMTimeSeriesModel(input_dim=input_dim, lstm_units=lstm_units).to(device)\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "            \n",
    "            # Train model for num_epochs\n",
    "            for epoch in range(num_epochs):\n",
    "                train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            test_loss = evaluate(model, test_loader, criterion, device)\n",
    "            avg_loss += test_loss\n",
    "            fold_count += 1\n",
    "        \n",
    "        return avg_loss / fold_count\n",
    "\n",
    "    # Create and run the study\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=n_trials, n_jobs=-1)  # Parallel or single-thread\n",
    "\n",
    "    return study.best_params\n",
    "\n",
    "\n",
    "best_hyperparameters = run_optuna_study(X_scaled, y_scaled, time_steps, num_epochs, n_splits=5, n_trials=10)\n",
    "print(\"Best Hyperparams:\", best_hyperparameters)\n",
    "\n",
    "\n",
    "# Train the model using the best hyperparameters\n",
    "# Suppose you got these from `best_hyperparameters`\n",
    "num_lstm_units = best_hyperparameters['lstm_units']\n",
    "learning_rate  = best_hyperparameters['learning_rate']\n",
    "batch_size     = best_hyperparameters['batch_size']\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create a single DataLoader over the entire dataset\n",
    "full_loader = create_torch_dataloader(X_scaled, y_scaled, time_steps, batch_size)\n",
    "\n",
    "model_lstm = LSTMTimeSeriesModel(\n",
    "    input_dim=X_scaled.shape[1], \n",
    "    lstm_units=num_lstm_units\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model_lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "# num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch(model_lstm, full_loader, criterion, optimizer, device)\n",
    "    # If desired, implement an early stopping check here\n",
    "    # ...\n",
    "    # print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.6f}\")\n",
    "\n",
    "# Optionally save your final model weights\n",
    "checkpoint_filepath = os.path.abspath(r\"C:\\Users\\MattBorgeson\\OneDrive - B&R Capital\\Programming Projects\\Rent Growth Forecasting\\Output Files\\Best Model Weights/best_model_fold_torch (Quarterly).pt\")\n",
    "# checkpoint_filepath = os.path.abspath(\"best_model_fold_torch.pt\")\n",
    "torch.save(model_lstm.state_dict(), checkpoint_filepath)\n",
    "\n",
    "# To load them later:\n",
    "# model_lstm.load_state_dict(torch.load(checkpoint_filepath))\n",
    "# model_lstm.eval()\n",
    "\n",
    "\n",
    "# Autoregressive Forecasting with LSTM\n",
    "model_lstm.eval()\n",
    "\n",
    "last_sequence = X_scaled[-time_steps:].copy()  # shape: (time_steps, num_features)\n",
    "ml_optimized_predictions = []\n",
    "\n",
    "\n",
    "forecast_num_steps = 10  # e.g., 10 future steps\n",
    "for _ in range(forecast_num_steps):\n",
    "    # (1) Reshape for model: [batch_size=1, time_steps, num_features]\n",
    "    seq_input = torch.tensor(last_sequence, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    \n",
    "    # (2) Predict\n",
    "    with torch.no_grad():\n",
    "        next_value_scaled_tensor = model_lstm(seq_input)  # shape: [1, 1]\n",
    "    \n",
    "    next_value_scaled = next_value_scaled_tensor.cpu().numpy().reshape(-1, 1)\n",
    "    \n",
    "    # (3) Inverse transform from scaled to original\n",
    "    next_value_original_scale = scaler_y.inverse_transform(next_value_scaled)\n",
    "    ml_optimized_predictions.append(next_value_original_scale[0, 0])\n",
    "    \n",
    "    # (4) Update the last_sequence with this new predicted value\n",
    "    #     If your target is the 1st column, place it there:\n",
    "    next_features = np.zeros((1, last_sequence.shape[1]))\n",
    "    next_value_rescaled = scaler_y.transform(next_value_original_scale)  # scale back for model continuity\n",
    "    next_features[0, 0] = next_value_rescaled[0, 0]\n",
    "    \n",
    "    # Shift and append\n",
    "    last_sequence = np.vstack([last_sequence[1:], next_features])\n",
    "\n",
    "ml_optimized_forecast_df = arima_forecast_df.copy(deep=True)\n",
    "ml_optimized_forecast_df[\"Machine Learning Optimized Forecast\"] = ml_optimized_predictions\n",
    "ml_optimized_forecast_df.drop(columns=['ARIMA Forecasted Rent Growth (%)'], inplace=True, errors='ignore')\n",
    "ml_optimized_forecast_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############################################################\n",
    "# ------------------ 7. Summary & Outputs ------------------ #\n",
    "rent_growth_forecasts_df = arima_forecast_df.copy(deep=True)\n",
    "rent_growth_forecasts_df[\"Machine Learning Optimized Forecast\"] = list(ml_optimized_forecast_df[\"Machine Learning Optimized Forecast\"])\n",
    "rent_growth_forecasts_df['Vector Autoregression (VAR) Forecast'] = list(var_forecast_df['Annual Rent Growth (%)'])\n",
    "rent_growth_forecasts_df.rename(columns={'ARIMA Forecasted Rent Growth (%)':'ARIMA Forecast'}, inplace=True)\n",
    "\n",
    "\n",
    "# print(f\"Ridge Regression R^2 on Train: {train_r2}, Test: {test_r2}\")\n",
    "# print(f\"Random Forest R^2 on Test: {rf_r2}\")\n",
    "\n",
    "\n",
    "var_forecast_df.rename(columns={'Annual Rent Growth (%)':'Vector Autoregression (VAR) Forecast'}, inplace=True)\n",
    "print(\"Forecast Type -- Vector Autoregression Analysis\")\n",
    "print(\"Forecast Tools -- Statsmodels\")\n",
    "print(f\"VAR Forecast:\")\n",
    "print(var_forecast_df['Vector Autoregression (VAR) Forecast'])\n",
    "\n",
    "\n",
    "print(\"Forecast Type -- Autoregressive Integrated Moving Average (ARIMA) Analysis\")\n",
    "print(\"Forecast Tools -- Statsmodels\")\n",
    "print(f\"ARIMA Forecast:\")\n",
    "print(arima_forecast_df['ARIMA Forecasted Rent Growth (%)'])\n",
    "\n",
    "\n",
    "print(\"Forecast Type -- Machine Learning/Neural Network Forecasting Using Optimized Independent Variable/Parameter Weights\")\n",
    "print(\"Forecast Tools -- PyTorch & Optuna\")\n",
    "# print(f\"Forecasted values for the next {forecast_num_steps} time steps:\")\n",
    "print(f\"Machine Learning Optimized Forecast:\")\n",
    "print(ml_optimized_forecast_df[\"Machine Learning Optimized Forecast\"])\n",
    "\n",
    "\n",
    "# Save the Forecasts DataFrame with all forecasts to an Excel file\n",
    "forecasting_analysis_outputs_file_path = os.path.abspath(r'C:\\Users\\MattBorgeson\\OneDrive - B&R Capital\\Programming Projects\\Rent Growth Forecasting\\Output Files\\Forecasts')\n",
    "\n",
    "\n",
    "var_forecast_file_path = os.path.abspath(f'{forecasting_analysis_outputs_file_path}\\\\VAR Forecast Model Forecasts (Annual).xlsx')\n",
    "arima_forecast_file_path = os.path.abspath(f'{forecasting_analysis_outputs_file_path}\\\\ARIMA Forecast Model Forecasts (Annual).xlsx')\n",
    "ml_optimized_forecast_file_path = os.path.abspath(f'{forecasting_analysis_outputs_file_path}\\\\Machine Learning Forecast Model Forecasts (Annual).xlsx')\n",
    "all_forecasts_file_path = os.path.abspath(f'{forecasting_analysis_outputs_file_path}\\\\All Forecast Methodologies Forecasts (Annual).xlsx')\n",
    "\n",
    "\n",
    "# var_forecast_df.to_excel(var_forecast_file_path, index=False)\n",
    "# arima_forecast_df.to_excel(arima_forecast_file_path, index=False)\n",
    "# ml_optimized_forecast_df.to_excel(ml_optimized_forecast_file_path, index=False)\n",
    "rent_growth_forecasts_df.to_excel(all_forecasts_file_path, index=False)\n",
    "\n",
    "\n",
    "\n",
    "##############################################################\n",
    "# -------------------- 8. Code Run Time -------------------- #\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "elapsed_time = (elapsed_time/60)\n",
    "elapsed_time = round(elapsed_time, 2)\n",
    "print(f\"Elapsed time: {elapsed_time} minutes\")\n",
    "\n",
    "def code_completion_notification ():\n",
    "    engine = pyttsx3.init()\n",
    "    # engine.endLoop()    \n",
    "    \n",
    "    try:\n",
    "        engine.endLoop()\n",
    "        del engine\n",
    "        engine = pyttsx3.init()\n",
    "    except:\n",
    "        pass\n",
    "        code_run_time = f\"The code took {elapsed_time} minutes to run.\"\n",
    "        text = \"Annual Rent Growth Forecast Analysis Complete.\"\n",
    "        text = f\"{text} {code_run_time}\"\n",
    "\n",
    "        engine.setProperty('rate', 225)\n",
    "\n",
    "        volume = engine.getProperty('volume')\n",
    "        engine.setProperty('volume', volume+0.50)\n",
    "\n",
    "        winsound.Beep(750, 1250)\n",
    "        engine.say(text)\n",
    "\n",
    "        engine.startLoop(False)\n",
    "        engine.iterate()\n",
    "        engine.endLoop()        \n",
    "\n",
    "\n",
    "code_completion_notification ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.A.4) SINGLE-CELL CONSOLIDATED CODE (QUARTERLY ANALYSIS CELL & ANNUAL ANALYSIS CELL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.A.4.1) SINGLE-CELL CONSOLIDATED CODE -- PACKAGE IMPORTS FOR CONVERTING NOTEBOOK CELLS TO PYTHON FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/MattBorgeson/OneDrive - B&R Capital/Programming Projects/Rent Growth Forecasting/Python Files/Quarterly Rent Growth Forecasts.py'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'C:/Users/MattBorgeson/OneDrive - B&R Capital/Programming Projects/Rent Growth Forecasting/Python Files/Annual Rent Growth Forecasts.py'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import matplotlib_inline\n",
    "\n",
    "%matplotlib inline\n",
    "# %quickref\n",
    "# %magic\n",
    "\n",
    "\n",
    "python_files_folder = 'C:/Users/MattBorgeson/OneDrive - B&R Capital/Programming Projects/Rent Growth Forecasting/Python Files/'\n",
    "quarterly_rent_growth_analysis_path = f\"{python_files_folder}Quarterly Rent Growth Forecasts.py\"\n",
    "annual_rent_growth_analysis_path = f\"{python_files_folder}Annual Rent Growth Forecasts.py\"\n",
    "\n",
    "quarterly_rent_growth_analysis_path\n",
    "annual_rent_growth_analysis_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.A.4.2) SINGLE-CELL CONSOLIDATED CODE -- CREATE RENT GROWTH FORECAST (QUARTERLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting C:/Users/MattBorgeson/OneDrive - B&R Capital/Programming Projects/Rent Growth Forecasting/Python Files/Quarterly Rent Growth Forecasts.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"{python_files_folder}Quarterly Rent Growth Forecasts.py\"\n",
    "###############################################################################################################\n",
    "########################################## PYTHON PACKAGES TO IMPORT ##########################################\n",
    "###############################################################################################################\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import enum\n",
    "import winsound\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline\n",
    "\n",
    "\n",
    "import IPython\n",
    "from IPython import get_ipython, paths\n",
    "from IPython.paths import get_ipython_dir, get_ipython_module_path, get_ipython_package_dir\n",
    "from IPython import display, extensions, extract_module_locals, Application\n",
    "from IPython.display import HTML, SVG, YouTubeVideo, set_matplotlib_formats, FileLink, IFrame\n",
    "from IPython.display import display, Pretty, DisplayHandle, DisplayObject\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "# from pylab import *\n",
    "\n",
    "\n",
    "import nbformat\n",
    "from nbformat import read\n",
    "import notebook\n",
    "from notebook import notebookapp, auth, serverextensions, extensions, utils\n",
    "from notebook import nbextensions, nbconvert\n",
    "\n",
    "\n",
    "import ipywidgets\n",
    "from ipywidgets import AppLayout, FloatLogSlider, load_ipython_extension, widgets\n",
    "\n",
    "import ipydatetime\n",
    "import ipyparallel\n",
    "import ipympl\n",
    "import ipyleaflet\n",
    "\n",
    "# import jupyterthemes\n",
    "# from jupyterthemes import get_themes, install_theme, fonts, styles, layout\n",
    "# import jupyterlab_sql\n",
    "# from jupyterlab_sql import load_jupyter_server_extension\n",
    "\n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "import sktime\n",
    "from sktime.datasets import load_airline, load_longley\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "# from sktime.forecasting.arima import AutoARIMA\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.forecasting.theta import ThetaForecaster\n",
    "# from sktime.forecasting.var import VAR\n",
    "from sktime.utils.plotting import plot_series\n",
    "from sktime.datatypes import get_examples\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.performance_metrics.forecasting import mean_absolute_percentage_error\n",
    "from sktime.forecasting.fbprophet import Prophet\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "# import keras\n",
    "# import tensorflow\n",
    "# # Keras API for building and training models\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# # TensorFlow device management (to inspect hardware like GPUs/CPUs)\n",
    "# from tensorflow.python.framework import config \n",
    "# from tensorflow.python.client import device_lib\n",
    "# # TensorFlow build information (for debugging CUDA/cuDNN versions, etc.)\n",
    "# from tensorflow.python.platform import build_info\n",
    "\n",
    "import optuna\n",
    "\n",
    "import openpyxl\n",
    "import pyttsx3\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "############################### EXCEL DATA FILE PATHS ###############################\n",
    "#####################################################################################\n",
    "user_name = \"MattBorgeson\"\n",
    "\n",
    "fred_data_directory = os.path.abspath(r'C:\\Users\\MattBorgeson\\OneDrive - B&R Capital\\Programming Projects\\Rent Growth Forecasting\\Input Files\\Fred Data')\n",
    "fred_data_file_name_selection = os.listdir(fred_data_directory)[1]\n",
    "fred_data_file_path = os.path.abspath(f'{fred_data_directory}\\\\{fred_data_file_name_selection}')\n",
    "\n",
    "market_analysis_directory = os.path.abspath(r'C:\\Users\\MattBorgeson\\OneDrive - B&R Capital\\Programming Projects\\Rent Growth Forecasting\\Input Files\\Market Analyses')\n",
    "market_analysis_file_name_selection = os.listdir(market_analysis_directory)[1]\n",
    "market_analysis_file_path = os.path.abspath(f'{market_analysis_directory }\\\\{market_analysis_file_name_selection}')\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "##################### READING EXISTING ANALYSES INTO DATAFRAMES #####################\n",
    "#####################################################################################\n",
    "os.listdir(fred_data_directory)\n",
    "os.listdir(market_analysis_directory)\n",
    "\n",
    "os.listdir(fred_data_directory)[1]\n",
    "os.listdir(market_analysis_directory)[1]\n",
    "\n",
    "market_analysis_df = pd.read_excel(market_analysis_file_path)\n",
    "fred_data_df = pd.read_excel(fred_data_file_path)\n",
    "market_analysis_df\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "######################## PYTORCH HARDWARE UTILIZATION CHECK #########################\n",
    "#####################################################################################\n",
    "print(torch.__version__)             # Prints the PyTorch version\n",
    "print(torch.cuda.is_available())     # True if a compatible GPU is accessible\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA is not available\")\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Create a random 2D tensor on the selected device\n",
    "x = torch.rand((3, 3), device=device)\n",
    "print(\"Tensor x:\", x)\n",
    "print(\"Tensor x is on:\", x.device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######################################################################################################################\n",
    "#################################### CREATE THE MERGED DATAFRAME & EXPORT TO EXCEL ####################################\n",
    "#######################################################################################################################\n",
    "market_analysis_df = pd.read_excel(market_analysis_file_path)\n",
    "fred_data_df = pd.read_excel(fred_data_file_path)\n",
    "\n",
    "\n",
    "merged_data_df = pd.merge(market_analysis_df, fred_data_df, left_on=\"Analysis Date\", right_on=\"Adjusted Analysis Date\", how='inner')\n",
    "merged_data_df.rename(columns={\"Analysis Date_x\":\"Analysis Date\"}, inplace=True)\n",
    "merged_data_df.rename(columns={\"Adjusted Analysis Day\":\"Analysis Day\"}, inplace=True)\n",
    "\n",
    "\n",
    "# analysis_day_col = merged_data_df.pop(\"Analysis Day\")\n",
    "# merged_data_df.insert(3, \"Analysis Day\", analysis_day_col)\n",
    "\n",
    "# merged_data_col_drop_list = [\n",
    "#     \"Analysis Date_y\",\n",
    "#     \"Adjusted Analysis Date\",\n",
    "#     \"Adjusted Analysis Year\",\n",
    "#     \"Adjusted Analysis Month\",\n",
    "#     \"Analysis Year\",\n",
    "#     \"Analysis Month\",\n",
    "#     \"Analysis Day\",\n",
    "#     \"Annual Rent Growth (%)\",\n",
    "#     \"Annual Rent Growth (%) - Lagged\",\n",
    "#     \"Stabilized Vacancy (%)\",\n",
    "#     \"Market Asking Rent/Unit ($)\",\n",
    "# ]\n",
    "\n",
    "# merged_data_df.drop(columns=merged_data_col_drop_list, inplace=True)\n",
    "# merged_data_df\n",
    "\n",
    "\n",
    "\n",
    "merged_data_col_list = [\n",
    "    \"Analysis Date\",\n",
    "    \"Market Name\",\n",
    "\n",
    "    # \"Annual Rent Growth (%)\",\n",
    "    # \"Annual Rent Growth (%) - Lagged\",\n",
    "    \"Quarterly Rent Growth (%)\",\n",
    "    # \"Quarterly Rent Growth (%) - Lagged\",\n",
    "\n",
    "    \"Inventory (# Units)\",\n",
    "    \"Under Construction (# Units)\",\n",
    "    \"Under Construction (% of Inventory)\",\n",
    "    \"Total Occupancy (# Units)\",\n",
    "    \"Total Vacancy (# Units)\",\n",
    "    \n",
    "    \"Quarterly Net Deliveries (# Units)\",\n",
    "    \"Quarterly Construction Starts (# Units)\",\n",
    "    \"Quarterly Net Absorption (# Units)\",\n",
    "    \"Absorption - Prior 12 Months (# Units)\",\n",
    "    \"Net Deliveries - Prior 12 Months (# Units)\",\n",
    "\n",
    "    \"Unemployment Rate (%)\",\n",
    "    \"Job Growth (%)\",\n",
    "    \"Population (#)\",\n",
    "    \"Population Growth (%)\",\n",
    "    \"Median Household Income ($)\",\n",
    "    \"Median Household Income Growth (%)\",\n",
    "\n",
    "    \"Federal Funds Effective Rate\",\n",
    "\n",
    "    \"Consumer Price Index for All Urban Consumers: All Items in U.S. City Average\",\n",
    "\n",
    "    \"Unemployed Persons in Phoenix-Mesa-Scottsdale, AZ (MSA)\",\n",
    "    \"Employed Persons in Phoenix-Mesa-Scottsdale, AZ (MSA)\",\n",
    "    \"Civilian Labor Force in Phoenix-Mesa-Scottsdale, AZ (MSA)\",\n",
    "    \"Unemployment Rate in Phoenix-Mesa-Scottsdale, AZ (MSA)\",\n",
    "\n",
    "    \"S&P CoreLogic Case-Shiller AZ-Phoenix Home Price Index\",\n",
    "]\n",
    "\n",
    "\n",
    "quarterly_forecast_merged_data_df = merged_data_df[merged_data_col_list]\n",
    "\n",
    "quarterly_forecast_merged_data_df = quarterly_forecast_merged_data_df[quarterly_forecast_merged_data_df != '-']\n",
    "quarterly_forecast_merged_data_df[\"Quarterly Rent Growth (%)\"] = quarterly_forecast_merged_data_df[\"Quarterly Rent Growth (%)\"].astype('float')\n",
    "quarterly_forecast_merged_data_df.dropna(inplace=True)\n",
    "quarterly_forecast_merged_data_df.reset_index(inplace=True)\n",
    "quarterly_forecast_merged_data_df.drop(columns=['index'], inplace=True)\n",
    "\n",
    "\n",
    "############ Export the merged Dataframe to Excel\n",
    "quarterly_forecast_merged_data_file_path = os.path.abspath(f'{fred_data_directory}\\\\Rent Growth Forecast (Quarterly) - Merged Data (Fred Series Data & Phoenix Market Data).xlsx')\n",
    "quarterly_forecast_merged_data_df.to_excel(quarterly_forecast_merged_data_file_path, index=False)\n",
    "\n",
    "merged_data_df = merged_data_df[merged_data_col_list]\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "################################# ALL STATISTICAL CODE IN A SINGLE CELL #################################\n",
    "#########################################################################################################\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the dataset\n",
    "merged_data_file_path = os.path.abspath(f'{fred_data_directory}\\\\Rent Growth Forecast (Quarterly) - Merged Data (Fred Series Data & Phoenix Market Data).xlsx')\n",
    "merged_data = pd.read_excel(merged_data_file_path)\n",
    "merged_data.dropna(inplace=True)\n",
    "\n",
    "# Handle missing values with forward fill\n",
    "df_filled = merged_data.fillna(method='ffill')\n",
    "\n",
    "\n",
    "#################################### Add interaction terms ####################################\n",
    "##### Interaction Type - Multiplication\n",
    "df_filled['Job-Population Interaction'] = df_filled['Job Growth (%)'] * df_filled['Population Growth (%)']\n",
    "df_filled['Income-Population Interaction'] = df_filled['Median Household Income Growth (%)'] * df_filled['Population Growth (%)']\n",
    "df_filled['Job-Income Interaction'] = df_filled['Job Growth (%)'] * df_filled['Median Household Income Growth (%)']\n",
    "df_filled['Job-Under Construction Interaction'] = df_filled['Job Growth (%)'] * df_filled['Under Construction (% of Inventory)']\n",
    "df_filled['Population-Under Construction Interaction'] = df_filled['Population Growth (%)'] * df_filled['Under Construction (% of Inventory)']\n",
    "\n",
    "##### Interaction Type - Division\n",
    "# df_filled['Absorption-Deliveries Interaction'] = df_filled['Absorption - Prior 12 Months (# Units)'] / df_filled['Net Deliveries - Prior 12 Months (# Units)']\n",
    "df_filled['Absorption-Deliveries Interaction'] = df_filled['Quarterly Net Absorption (# Units)'] / df_filled['Quarterly Net Deliveries (# Units)']\n",
    "\n",
    "df_filled['Under Construction-Inventory Interaction'] = df_filled['Under Construction (# Units)'] / df_filled['Inventory (# Units)']\n",
    "# df_filled['Deliveries-Inventory Interaction'] = df_filled['Net Deliveries - Prior 12 Months (# Units)'] / df_filled['Inventory (# Units)']\n",
    "df_filled['Deliveries-Inventory Interaction'] = df_filled['Quarterly Net Deliveries (# Units)'] / df_filled['Inventory (# Units)']\n",
    "\n",
    "df_filled['Occupancy-Inventory Interaction'] = df_filled['Total Occupancy (# Units)'] / df_filled['Inventory (# Units)']\n",
    "df_filled['Vacancy-Inventory Interaction'] = df_filled['Total Vacancy (# Units)'] / df_filled['Inventory (# Units)']\n",
    "df_filled['Unemployed-Labor Force Interaction'] = df_filled['Unemployed Persons in Phoenix-Mesa-Scottsdale, AZ (MSA)'] / df_filled['Civilian Labor Force in Phoenix-Mesa-Scottsdale, AZ (MSA)']\n",
    "df_filled['Employed-Labor Force Interaction'] = df_filled['Employed Persons in Phoenix-Mesa-Scottsdale, AZ (MSA)'] / df_filled['Civilian Labor Force in Phoenix-Mesa-Scottsdale, AZ (MSA)']\n",
    "\n",
    "\n",
    "# Add lagged variables for independent variables\n",
    "df_filled['Unemployment Rate Lagged'] = df_filled['Unemployment Rate (%)'].shift(1)\n",
    "df_filled['Job Growth Lagged'] = df_filled['Job Growth (%)'].shift(1)\n",
    "df_filled['Population Growth Lagged'] = df_filled['Population Growth (%)'].shift(1)\n",
    "\n",
    "# df_filled['Unemployment Rate Lagged'] = df_filled['Unemployment Rate (%)'].shift(4)\n",
    "# df_filled['Job Growth Lagged'] = df_filled['Job Growth (%)'].shift(4)\n",
    "# df_filled['Population Growth Lagged'] = df_filled['Population Growth (%)'].shift(4)\n",
    "\n",
    "\n",
    "# Drop rows with NaN values caused by lagging\n",
    "df_filled = df_filled.dropna()\n",
    "\n",
    "# Define independent and dependent variables\n",
    "X = df_filled[[\n",
    "    'Job-Population Interaction',\n",
    "    'Income-Population Interaction',\n",
    "    'Job-Income Interaction',\n",
    "    'Job-Under Construction Interaction',\n",
    "    'Population-Under Construction Interaction',\n",
    "\n",
    "    'Absorption-Deliveries Interaction',\n",
    "    'Under Construction-Inventory Interaction',\n",
    "    'Deliveries-Inventory Interaction',\n",
    "\n",
    "    'Occupancy-Inventory Interaction',\n",
    "    'Vacancy-Inventory Interaction',\n",
    "    'Unemployed-Labor Force Interaction',\n",
    "    'Employed-Labor Force Interaction',\n",
    "\n",
    "    # 'Quarterly Rent Growth (%) - Lagged',\n",
    "    'Unemployment Rate Lagged',\n",
    "    'Job Growth Lagged',\n",
    "    'Population Growth Lagged',\n",
    "\n",
    "    # 'Inventory (# Units)',\n",
    "    # 'Under Construction (# Units)',\n",
    "    'Under Construction (% of Inventory)',\n",
    "    # 'Absorption - Prior 12 Months (# Units)', \n",
    "    'Quarterly Net Absorption (# Units)',\n",
    "    # 'Net Deliveries - Prior 12 Months (# Units)',\n",
    "    'Quarterly Net Deliveries (# Units)',\n",
    "\n",
    "    # 'Unemployment Rate (%)',\n",
    "    # 'Job Growth (%)',\n",
    "    # 'Population (#)',\n",
    "    # 'Population Growth (%)', \n",
    "    'Median Household Income ($)',\n",
    "    'Median Household Income Growth (%)',\n",
    "               ]]\n",
    "\n",
    "y = df_filled['Quarterly Rent Growth (%)']\n",
    "\n",
    "# Add constant for the regression intercept\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "\n",
    "\n",
    "##################################################################\n",
    "# ------------------ 1. Out-of-Sample Testing ------------------ #\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Ridge regression with cross-validation hyperparameter tuning\n",
    "ridge_params = {'alpha': [0.01, 0.1, 1.0, 10, 100]}\n",
    "ridge_model = Ridge()\n",
    "ridge_cv = GridSearchCV(ridge_model, ridge_params, cv=TimeSeriesSplit(n_splits=5), scoring='r2')\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "# Best model from cross-validation\n",
    "ridge_best = ridge_cv.best_estimator_\n",
    "\n",
    "# Predictions on test set\n",
    "ridge_predictions_train = ridge_best.predict(X_train)\n",
    "ridge_predictions_test = ridge_best.predict(X_test)\n",
    "\n",
    "# Ridge model performance\n",
    "train_r2 = r2_score(y_train, ridge_predictions_train)\n",
    "test_r2 = r2_score(y_test, ridge_predictions_test)\n",
    "\n",
    "# Residual analysis\n",
    "residuals = y_test - ridge_predictions_test\n",
    "# print(\"Residuals summary:\")\n",
    "# print(residuals.describe())\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# ------------------ 2. Vector Autoregression (VAR) ------------------ #\n",
    "# Create VAR model using key time series\n",
    "df_var = df_filled[[\n",
    "    'Quarterly Rent Growth (%)',\n",
    "\n",
    "    'Job-Population Interaction',\n",
    "    'Income-Population Interaction',\n",
    "    'Job-Income Interaction',\n",
    "    'Job-Under Construction Interaction',\n",
    "    'Population-Under Construction Interaction',\n",
    "\n",
    "    'Absorption-Deliveries Interaction',\n",
    "    'Under Construction-Inventory Interaction',\n",
    "    'Deliveries-Inventory Interaction',\n",
    "\n",
    "    'Occupancy-Inventory Interaction',\n",
    "    'Vacancy-Inventory Interaction',\n",
    "    'Unemployed-Labor Force Interaction',\n",
    "    'Employed-Labor Force Interaction',\n",
    "\n",
    "    'Unemployment Rate Lagged',\n",
    "    'Job Growth Lagged',\n",
    "    'Population Growth Lagged',\n",
    "\n",
    "    'Under Construction (% of Inventory)',\n",
    "\n",
    "    # 'Absorption - Prior 12 Months (# Units)', \n",
    "    'Quarterly Net Absorption (# Units)',\n",
    "    # 'Net Deliveries - Prior 12 Months (# Units)',\n",
    "    'Quarterly Net Deliveries (# Units)',\n",
    "\n",
    "    'Unemployment Rate (%)',\n",
    "    'Job Growth (%)',\n",
    "    'Population Growth (%)', \n",
    "    'Median Household Income Growth (%)',\n",
    "    ]]\n",
    "model_var = VAR(df_var)\n",
    "var_results = model_var.fit(maxlags=2)\n",
    "\n",
    "# Forecast periods using VAR\n",
    "# var_forecast_periods = 5\n",
    "var_forecast_periods = 10\n",
    "# var_forecast_periods = 20\n",
    "\n",
    "var_forecast = var_results.forecast(df_var.values[-var_results.k_ar:], steps=var_forecast_periods)\n",
    "var_forecast_df = pd.DataFrame(var_forecast, columns=df_var.columns)\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "# ------------------ 3. ARIMA Time Series Forecasting ------------------ #\n",
    "# Differencing to make the data stationary\n",
    "df_filled['Quarterly Rent Growth Diff'] = df_filled['Quarterly Rent Growth (%)'].diff().dropna()\n",
    "\n",
    "# ARIMA model (order based on dataset properties, p=1, d=1, q=1 as an example)\n",
    "arima_model = ARIMA(df_filled['Quarterly Rent Growth (%)'].dropna(), order=(1, 1, 1))\n",
    "arima_results = arima_model.fit()\n",
    "\n",
    "# future_periods = 5\n",
    "future_periods = 10\n",
    "# future_periods = 20\n",
    "\n",
    "arima_forecast = arima_results.forecast(steps=future_periods)\n",
    "\n",
    "\n",
    "# Create future dates for the forecast\n",
    "last_dataset_date = df_filled['Analysis Date'].max()\n",
    "first_future_date = pd._libs.tslibs.timestamps.Timestamp(year=last_dataset_date.year, month=last_dataset_date.month + 1, day=last_dataset_date.day)\n",
    "\n",
    "future_dates = pd.date_range(start=first_future_date, periods=future_periods, freq='QE', inclusive='right')\n",
    "\n",
    "\n",
    "# Combine future dates and ARIMA forecast values\n",
    "arima_forecast_df = pd.DataFrame({\n",
    "    'Forecasted Date': future_dates,\n",
    "    'ARIMA Forecasted Rent Growth (%)': arima_forecast\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################################################\n",
    "# ------------------ 4. Random Forest (Ensemble Method) ------------------ #\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Random forest performance\n",
    "rf_r2 = r2_score(y_test, rf_predictions)\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# ------------------ 5. LSTM Neural Network for Time Series ------------------ #\n",
    "\n",
    "# Set environment variables for threads (similar idea to TensorFlow's environment vars)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"  # Controls OpenMP threads\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"4\"  # For MKL (if used internally)\n",
    "\n",
    "# Then in your Python code:\n",
    "torch.set_num_threads(4)  # Ensures PyTorch uses 2 threads internally\n",
    "\n",
    "\n",
    "# Create a custom pytorch dataset and retun a dataloader\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch dataset for creating sequences of length `time_steps`\n",
    "    from a 2D feature array X and 1D array y.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, time_steps):\n",
    "        \"\"\"\n",
    "        X: numpy array of shape [num_samples, num_features]\n",
    "        y: numpy array of shape [num_samples]\n",
    "        time_steps: int, number of past timesteps to include in each sample\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.time_steps = time_steps\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of valid sequences = total samples - time_steps\n",
    "        return len(self.X) - self.time_steps\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Sequences range from idx to idx + time_steps\n",
    "        x_seq = self.X[idx : idx + self.time_steps]\n",
    "        y_label = self.y[idx + self.time_steps]  # label at the end of the window\n",
    "        # Convert to float32 tensors\n",
    "        x_seq = torch.tensor(x_seq, dtype=torch.float32)\n",
    "        y_label = torch.tensor(y_label, dtype=torch.float32)\n",
    "        return x_seq, y_label\n",
    "\n",
    "\n",
    "def create_torch_dataloader(X, y, time_steps, batch_size):\n",
    "    \"\"\"\n",
    "    Create a PyTorch DataLoader for time series data.\n",
    "    \"\"\"\n",
    "    dataset = TimeSeriesDataset(X, y, time_steps)\n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False,   # Typically don't shuffle time series\n",
    "        drop_last=False  # Keep all samples\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "# Scaling Data\n",
    "# Example: X, y are your original time series data\n",
    "# They can be NumPy arrays or Pandas DataFrame/Series.\n",
    "\n",
    "scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)  # shape: [samples, features]\n",
    "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMTimeSeriesModel(nn.Module):\n",
    "    def __init__(self, input_dim, lstm_units):\n",
    "        \"\"\"\n",
    "        input_dim : number of features per timestep\n",
    "        lstm_units: hidden dimension (number of LSTM units)\n",
    "        \"\"\"\n",
    "        super(LSTMTimeSeriesModel, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=input_dim, hidden_size=lstm_units, batch_first=True, dropout=0.0)\n",
    "        self.lstm2 = nn.LSTM(input_size=lstm_units, hidden_size=lstm_units, batch_first=True, dropout=0.0)\n",
    "        self.fc = nn.Linear(lstm_units, 1)  # Final dense layer -> 1 output\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, time_steps, input_dim]\n",
    "        out, (h, c) = self.lstm1(x)  # out shape: [batch_size, time_steps, lstm_units]\n",
    "        out, (h, c) = self.lstm2(out)  # out shape: [batch_size, time_steps, lstm_units]\n",
    "        # Take the last timestep's output\n",
    "        last_timestep = out[:, -1, :]  # shape: [batch_size, lstm_units]\n",
    "        return self.fc(last_timestep)  # shape: [batch_size, 1]\n",
    "\n",
    "\n",
    "# Train and evaluate the mnodel using the dataloader\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for x_batch, y_batch in dataloader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs.view(-1), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * x_batch.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    eval_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in dataloader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs.view(-1), y_batch)\n",
    "            eval_loss += loss.item() * x_batch.size(0)\n",
    "\n",
    "    eval_loss = eval_loss / len(dataloader.dataset)\n",
    "    return eval_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "# -------- 6. Forecasting/Prediction with the Best Hyperparameters -------- #\n",
    "# Forecasting\n",
    "time_steps = 10\n",
    "num_epochs = 50\n",
    "\n",
    "\n",
    "def run_optuna_study(X_scaled, y_scaled, time_steps, num_epochs, n_splits=5, n_trials=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    def objective(trial):\n",
    "        # lstm_units = trial.suggest_int('lstm_units', 16, 64)\n",
    "        lstm_units = trial.suggest_int('lstm_units', 16, 128)        \n",
    "\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "\n",
    "        # batch_size = trial.suggest_categorical('batch_size', [16, 32])\n",
    "        batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
    "\n",
    "        avg_loss = 0.0\n",
    "        fold_count = 0\n",
    "\n",
    "        for train_idx, test_idx in tscv.split(X_scaled):\n",
    "            # Split data\n",
    "            X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "            y_train, y_test = y_scaled[train_idx], y_scaled[test_idx]\n",
    "            \n",
    "            # Create Dataloaders\n",
    "            train_loader = create_torch_dataloader(X_train, y_train, time_steps, batch_size)\n",
    "            test_loader  = create_torch_dataloader(X_test,  y_test,  time_steps, batch_size)\n",
    "            \n",
    "            # Build model\n",
    "            input_dim = X_train.shape[1]\n",
    "            model = LSTMTimeSeriesModel(input_dim=input_dim, lstm_units=lstm_units).to(device)\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "            \n",
    "            # Train model for num_epochs\n",
    "            for epoch in range(num_epochs):\n",
    "                train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            test_loss = evaluate(model, test_loader, criterion, device)\n",
    "            avg_loss += test_loss\n",
    "            fold_count += 1\n",
    "        \n",
    "        return avg_loss / fold_count\n",
    "\n",
    "    # Create and run the study\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=n_trials, n_jobs=-1)  # Parallel or single-thread\n",
    "\n",
    "    return study.best_params\n",
    "\n",
    "\n",
    "best_hyperparameters = run_optuna_study(X_scaled, y_scaled, time_steps, num_epochs, n_splits=5, n_trials=10)\n",
    "print(\"Best Hyperparams:\", best_hyperparameters)\n",
    "\n",
    "\n",
    "# Train the model using the best hyperparameters\n",
    "# Suppose you got these from `best_hyperparameters`\n",
    "num_lstm_units = best_hyperparameters['lstm_units']\n",
    "learning_rate  = best_hyperparameters['learning_rate']\n",
    "batch_size     = best_hyperparameters['batch_size']\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create a single DataLoader over the entire dataset\n",
    "full_loader = create_torch_dataloader(X_scaled, y_scaled, time_steps, batch_size)\n",
    "\n",
    "model_lstm = LSTMTimeSeriesModel(\n",
    "    input_dim=X_scaled.shape[1], \n",
    "    lstm_units=num_lstm_units\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model_lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "# num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch(model_lstm, full_loader, criterion, optimizer, device)\n",
    "    # If desired, implement an early stopping check here\n",
    "    # ...\n",
    "    # print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.6f}\")\n",
    "\n",
    "# Optionally save your final model weights\n",
    "checkpoint_filepath = os.path.abspath(r\"C:\\Users\\MattBorgeson\\OneDrive - B&R Capital\\Programming Projects\\Rent Growth Forecasting\\Output Files\\Best Model Weights/best_model_fold_torch (Quarterly).pt\")\n",
    "# checkpoint_filepath = os.path.abspath(\"best_model_fold_torch.pt\")\n",
    "torch.save(model_lstm.state_dict(), checkpoint_filepath)\n",
    "\n",
    "# To load them later:\n",
    "# model_lstm.load_state_dict(torch.load(checkpoint_filepath))\n",
    "# model_lstm.eval()\n",
    "\n",
    "\n",
    "# Autoregressive Forecasting with LSTM\n",
    "model_lstm.eval()\n",
    "\n",
    "last_sequence = X_scaled[-time_steps:].copy()  # shape: (time_steps, num_features)\n",
    "ml_optimized_predictions = []\n",
    "\n",
    "\n",
    "forecast_num_steps = 10  # e.g., 10 future steps\n",
    "for _ in range(forecast_num_steps):\n",
    "    # (1) Reshape for model: [batch_size=1, time_steps, num_features]\n",
    "    seq_input = torch.tensor(last_sequence, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    \n",
    "    # (2) Predict\n",
    "    with torch.no_grad():\n",
    "        next_value_scaled_tensor = model_lstm(seq_input)  # shape: [1, 1]\n",
    "    \n",
    "    next_value_scaled = next_value_scaled_tensor.cpu().numpy().reshape(-1, 1)\n",
    "    \n",
    "    # (3) Inverse transform from scaled to original\n",
    "    next_value_original_scale = scaler_y.inverse_transform(next_value_scaled)\n",
    "    ml_optimized_predictions.append(next_value_original_scale[0, 0])\n",
    "    \n",
    "    # (4) Update the last_sequence with this new predicted value\n",
    "    #     If your target is the 1st column, place it there:\n",
    "    next_features = np.zeros((1, last_sequence.shape[1]))\n",
    "    next_value_rescaled = scaler_y.transform(next_value_original_scale)  # scale back for model continuity\n",
    "    next_features[0, 0] = next_value_rescaled[0, 0]\n",
    "    \n",
    "    # Shift and append\n",
    "    last_sequence = np.vstack([last_sequence[1:], next_features])\n",
    "\n",
    "ml_optimized_forecast_df = arima_forecast_df.copy(deep=True)\n",
    "ml_optimized_forecast_df[\"Machine Learning Optimized Forecast\"] = ml_optimized_predictions\n",
    "ml_optimized_forecast_df.drop(columns=['ARIMA Forecasted Rent Growth (%)'], inplace=True, errors='ignore')\n",
    "ml_optimized_forecast_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############################################################\n",
    "# ------------------ 7. Summary & Outputs ------------------ #\n",
    "rent_growth_forecasts_df = arima_forecast_df.copy(deep=True)\n",
    "rent_growth_forecasts_df[\"Machine Learning Optimized Forecast\"] = list(ml_optimized_forecast_df[\"Machine Learning Optimized Forecast\"])\n",
    "rent_growth_forecasts_df['Vector Autoregression (VAR) Forecast'] = list(var_forecast_df['Quarterly Rent Growth (%)'])\n",
    "rent_growth_forecasts_df.rename(columns={'ARIMA Forecasted Rent Growth (%)':'ARIMA Forecast'}, inplace=True)\n",
    "\n",
    "\n",
    "# print(f\"Ridge Regression R^2 on Train: {train_r2}, Test: {test_r2}\")\n",
    "# print(f\"Random Forest R^2 on Test: {rf_r2}\")\n",
    "\n",
    "\n",
    "var_forecast_df.rename(columns={'Quarterly Rent Growth (%)':'Vector Autoregression (VAR) Forecast'}, inplace=True)\n",
    "print(\"Forecast Type -- Vector Autoregression Analysis\")\n",
    "print(\"Forecast Tools -- Statsmodels\")\n",
    "print(f\"VAR Forecast:\")\n",
    "print(var_forecast_df['Vector Autoregression (VAR) Forecast'])\n",
    "\n",
    "\n",
    "print(\"Forecast Type -- Autoregressive Integrated Moving Average (ARIMA) Analysis\")\n",
    "print(\"Forecast Tools -- Statsmodels\")\n",
    "print(f\"ARIMA Forecast:\")\n",
    "print(arima_forecast_df['ARIMA Forecasted Rent Growth (%)'])\n",
    "\n",
    "\n",
    "print(\"Forecast Type -- Machine Learning/Neural Network Forecasting Using Optimized Independent Variable/Parameter Weights\")\n",
    "print(\"Forecast Tools -- PyTorch & Optuna\")\n",
    "# print(f\"Forecasted values for the next {forecast_num_steps} time steps:\")\n",
    "print(f\"Machine Learning Optimized Forecast:\")\n",
    "print(ml_optimized_forecast_df[\"Machine Learning Optimized Forecast\"])\n",
    "\n",
    "\n",
    "# Save the Forecasts DataFrame with all forecasts to an Excel file\n",
    "forecasting_analysis_outputs_file_path = os.path.abspath(r'C:\\Users\\MattBorgeson\\OneDrive - B&R Capital\\Programming Projects\\Rent Growth Forecasting\\Output Files\\Forecasts')\n",
    "\n",
    "\n",
    "var_forecast_file_path = os.path.abspath(f'{forecasting_analysis_outputs_file_path}\\\\VAR Forecast Model Forecasts (Quarterly).xlsx')\n",
    "arima_forecast_file_path = os.path.abspath(f'{forecasting_analysis_outputs_file_path}\\\\ARIMA Forecast Model Forecasts (Quarterly).xlsx')\n",
    "ml_optimized_forecast_file_path = os.path.abspath(f'{forecasting_analysis_outputs_file_path}\\\\Machine Learning Forecast Model Forecasts (Quarterly).xlsx')\n",
    "all_forecasts_file_path = os.path.abspath(f'{forecasting_analysis_outputs_file_path}\\\\All Forecast Methodologies Forecasts (Quarterly).xlsx')\n",
    "\n",
    "\n",
    "# var_forecast_df.to_excel(var_forecast_file_path, index=False)\n",
    "# arima_forecast_df.to_excel(arima_forecast_file_path, index=False)\n",
    "# ml_optimized_forecast_df.to_excel(ml_optimized_forecast_file_path, index=False)\n",
    "rent_growth_forecasts_df.to_excel(all_forecasts_file_path, index=False)\n",
    "\n",
    "\n",
    "\n",
    "##############################################################\n",
    "# -------------------- 8. Code Run Time -------------------- #\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "elapsed_time = (elapsed_time/60)\n",
    "elapsed_time = round(elapsed_time, 2)\n",
    "print(f\"Elapsed time: {elapsed_time} minutes\")\n",
    "\n",
    "def code_completion_notification ():\n",
    "    engine = pyttsx3.init()\n",
    "    # engine.endLoop()    \n",
    "    \n",
    "    try:\n",
    "        engine.endLoop()\n",
    "        del engine\n",
    "        engine = pyttsx3.init()\n",
    "    except:\n",
    "        pass\n",
    "        code_run_time = f\"The code took {elapsed_time} minutes to run.\"\n",
    "        text = \"Quarterly Rent Growth Forecast Analysis Complete.\"\n",
    "        text = f\"{text} {code_run_time}\"\n",
    "\n",
    "        engine.setProperty('rate', 225)\n",
    "\n",
    "        volume = engine.getProperty('volume')\n",
    "        engine.setProperty('volume', volume+0.50)\n",
    "\n",
    "        winsound.Beep(750, 1250)\n",
    "        engine.say(text)\n",
    "\n",
    "        engine.startLoop(False)\n",
    "        engine.iterate()\n",
    "        engine.endLoop()        \n",
    "\n",
    "\n",
    "code_completion_notification ()\n",
    "# %run \"{python_files_folder}Quarterly Rent Growth Forecasts.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.A.4.3) SINGLE-CELL CONSOLIDATED CODE -- RUN RENT GROWTH FORECAST ANALYSES (QUARTERLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"{python_files_folder}Quarterly Rent Growth Forecasts.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.A.4.4) SINGLE-CELL CONSOLIDATED CODE -- CREATE RENT GROWTH FORECAST (ANNUAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting C:/Users/MattBorgeson/OneDrive - B&R Capital/Programming Projects/Rent Growth Forecasting/Python Files/Annual Rent Growth Forecasts.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"{python_files_folder}Annual Rent Growth Forecasts.py\"\n",
    "###############################################################################################################\n",
    "########################################## PYTHON PACKAGES TO IMPORT ##########################################\n",
    "###############################################################################################################\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import enum\n",
    "import winsound\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline\n",
    "\n",
    "\n",
    "import IPython\n",
    "from IPython import get_ipython, paths\n",
    "from IPython.paths import get_ipython_dir, get_ipython_module_path, get_ipython_package_dir\n",
    "from IPython import display, extensions, extract_module_locals, Application\n",
    "from IPython.display import HTML, SVG, YouTubeVideo, set_matplotlib_formats, FileLink, IFrame\n",
    "from IPython.display import display, Pretty, DisplayHandle, DisplayObject\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "# from pylab import *\n",
    "\n",
    "\n",
    "import nbformat\n",
    "from nbformat import read\n",
    "import notebook\n",
    "from notebook import notebookapp, auth, serverextensions, extensions, utils\n",
    "from notebook import nbextensions, nbconvert\n",
    "\n",
    "\n",
    "import ipywidgets\n",
    "from ipywidgets import AppLayout, FloatLogSlider, load_ipython_extension, widgets\n",
    "\n",
    "import ipydatetime\n",
    "import ipyparallel\n",
    "import ipympl\n",
    "import ipyleaflet\n",
    "\n",
    "# import jupyterthemes\n",
    "# from jupyterthemes import get_themes, install_theme, fonts, styles, layout\n",
    "# import jupyterlab_sql\n",
    "# from jupyterlab_sql import load_jupyter_server_extension\n",
    "\n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "import sktime\n",
    "from sktime.datasets import load_airline, load_longley\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "# from sktime.forecasting.arima import AutoARIMA\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.forecasting.theta import ThetaForecaster\n",
    "# from sktime.forecasting.var import VAR\n",
    "from sktime.utils.plotting import plot_series\n",
    "from sktime.datatypes import get_examples\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.performance_metrics.forecasting import mean_absolute_percentage_error\n",
    "from sktime.forecasting.fbprophet import Prophet\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "# import keras\n",
    "# import tensorflow\n",
    "# # Keras API for building and training models\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# # TensorFlow device management (to inspect hardware like GPUs/CPUs)\n",
    "# from tensorflow.python.framework import config \n",
    "# from tensorflow.python.client import device_lib\n",
    "# # TensorFlow build information (for debugging CUDA/cuDNN versions, etc.)\n",
    "# from tensorflow.python.platform import build_info\n",
    "\n",
    "import optuna\n",
    "\n",
    "import openpyxl\n",
    "import pyttsx3\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "############################### EXCEL DATA FILE PATHS ###############################\n",
    "#####################################################################################\n",
    "user_name = \"MattBorgeson\"\n",
    "\n",
    "fred_data_directory = os.path.abspath(r'C:\\Users\\MattBorgeson\\OneDrive - B&R Capital\\Programming Projects\\Rent Growth Forecasting\\Input Files\\Fred Data')\n",
    "fred_data_file_name_selection = os.listdir(fred_data_directory)[1]\n",
    "fred_data_file_path = os.path.abspath(f'{fred_data_directory}\\\\{fred_data_file_name_selection}')\n",
    "\n",
    "market_analysis_directory = os.path.abspath(r'C:\\Users\\MattBorgeson\\OneDrive - B&R Capital\\Programming Projects\\Rent Growth Forecasting\\Input Files\\Market Analyses')\n",
    "market_analysis_file_name_selection = os.listdir(market_analysis_directory)[1]\n",
    "market_analysis_file_path = os.path.abspath(f'{market_analysis_directory }\\\\{market_analysis_file_name_selection}')\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "##################### READING EXISTING ANALYSES INTO DATAFRAMES #####################\n",
    "#####################################################################################\n",
    "os.listdir(fred_data_directory)\n",
    "os.listdir(market_analysis_directory)\n",
    "\n",
    "os.listdir(fred_data_directory)[1]\n",
    "os.listdir(market_analysis_directory)[1]\n",
    "\n",
    "market_analysis_df = pd.read_excel(market_analysis_file_path)\n",
    "fred_data_df = pd.read_excel(fred_data_file_path)\n",
    "market_analysis_df\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "######################## PYTORCH HARDWARE UTILIZATION CHECK #########################\n",
    "#####################################################################################\n",
    "print(torch.__version__)             # Prints the PyTorch version\n",
    "print(torch.cuda.is_available())     # True if a compatible GPU is accessible\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA is not available\")\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Create a random 2D tensor on the selected device\n",
    "x = torch.rand((3, 3), device=device)\n",
    "print(\"Tensor x:\", x)\n",
    "print(\"Tensor x is on:\", x.device)\n",
    "\n",
    "\n",
    "\n",
    "#######################################################################################################################\n",
    "#################################### CREATE THE MERGED DATAFRAME & EXPORT TO EXCEL ####################################\n",
    "#######################################################################################################################\n",
    "market_analysis_df = pd.read_excel(market_analysis_file_path)\n",
    "fred_data_df = pd.read_excel(fred_data_file_path)\n",
    "\n",
    "\n",
    "merged_data_df = pd.merge(market_analysis_df, fred_data_df, left_on=\"Analysis Date\", right_on=\"Adjusted Analysis Date\", how='inner')\n",
    "merged_data_df.rename(columns={\"Analysis Date_x\":\"Analysis Date\"}, inplace=True)\n",
    "merged_data_df.rename(columns={\"Adjusted Analysis Day\":\"Analysis Day\"}, inplace=True)\n",
    "\n",
    "\n",
    "# analysis_day_col = merged_data_df.pop(\"Analysis Day\")\n",
    "# merged_data_df.insert(3, \"Analysis Day\", analysis_day_col)\n",
    "\n",
    "# merged_data_col_drop_list = [\n",
    "#     \"Analysis Date_y\",\n",
    "#     \"Adjusted Analysis Date\",\n",
    "#     \"Adjusted Analysis Year\",\n",
    "#     \"Adjusted Analysis Month\",\n",
    "#     \"Analysis Year\",\n",
    "#     \"Analysis Month\",\n",
    "#     \"Analysis Day\",\n",
    "#     \"Annual Rent Growth (%)\",\n",
    "#     \"Annual Rent Growth (%) - Lagged\",\n",
    "#     \"Stabilized Vacancy (%)\",\n",
    "#     \"Market Asking Rent/Unit ($)\",\n",
    "# ]\n",
    "\n",
    "# merged_data_df.drop(columns=merged_data_col_drop_list, inplace=True)\n",
    "# merged_data_df\n",
    "\n",
    "\n",
    "\n",
    "merged_data_col_list = [\n",
    "    \"Analysis Date\",\n",
    "    \"Market Name\",\n",
    "\n",
    "    \"Annual Rent Growth (%)\",\n",
    "    # \"Annual Rent Growth (%) - Lagged\",\n",
    "    # \"Quarterly Rent Growth (%)\",\n",
    "    # \"Quarterly Rent Growth (%) - Lagged\",\n",
    "\n",
    "    \"Inventory (# Units)\",\n",
    "    \"Under Construction (# Units)\",\n",
    "    \"Under Construction (% of Inventory)\",\n",
    "    \"Total Occupancy (# Units)\",\n",
    "    \"Total Vacancy (# Units)\",\n",
    "\n",
    "    \"Quarterly Net Deliveries (# Units)\",\n",
    "    \"Quarterly Construction Starts (# Units)\",\n",
    "    \"Quarterly Net Absorption (# Units)\",\n",
    "    \"Absorption - Prior 12 Months (# Units)\",\n",
    "    \"Net Deliveries - Prior 12 Months (# Units)\",\n",
    "\n",
    "    \"Unemployment Rate (%)\",\n",
    "    \"Job Growth (%)\",\n",
    "    \"Population (#)\",\n",
    "    \"Population Growth (%)\",\n",
    "    \"Median Household Income ($)\",\n",
    "    \"Median Household Income Growth (%)\",\n",
    "\n",
    "    \"Federal Funds Effective Rate\",\n",
    "\n",
    "    \"Consumer Price Index for All Urban Consumers: All Items in U.S. City Average\",\n",
    "\n",
    "    \"Unemployed Persons in Phoenix-Mesa-Scottsdale, AZ (MSA)\",\n",
    "    \"Employed Persons in Phoenix-Mesa-Scottsdale, AZ (MSA)\",\n",
    "    \"Civilian Labor Force in Phoenix-Mesa-Scottsdale, AZ (MSA)\",\n",
    "    \"Unemployment Rate in Phoenix-Mesa-Scottsdale, AZ (MSA)\",\n",
    "\n",
    "    \"S&P CoreLogic Case-Shiller AZ-Phoenix Home Price Index\",\n",
    "]\n",
    "\n",
    "\n",
    "annual_forecast_merged_data_df = merged_data_df[merged_data_col_list]\n",
    "\n",
    "annual_forecast_merged_data_df = annual_forecast_merged_data_df[annual_forecast_merged_data_df != '-']\n",
    "annual_forecast_merged_data_df[\"Annual Rent Growth (%)\"] = annual_forecast_merged_data_df[\"Annual Rent Growth (%)\"].astype('float')\n",
    "annual_forecast_merged_data_df.dropna(inplace=True)\n",
    "annual_forecast_merged_data_df.reset_index(inplace=True)\n",
    "annual_forecast_merged_data_df.drop(columns=['index'], inplace=True)\n",
    "\n",
    "\n",
    "############ Export the merged Dataframe to Excel\n",
    "annual_forecast_merged_data_file_path = os.path.abspath(f'{fred_data_directory}\\\\Rent Growth Forecast (Annual) - Merged Data (Fred Series Data & Phoenix Market Data).xlsx')\n",
    "annual_forecast_merged_data_df.to_excel(annual_forecast_merged_data_file_path, index=False)\n",
    "\n",
    "merged_data_df = merged_data_df[merged_data_col_list]\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "################################# ALL STATISTICAL CODE IN A SINGLE CELL #################################\n",
    "#########################################################################################################\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the dataset\n",
    "# merged_data_file_path = os.path.abspath(f'{fred_data_directory}\\\\Rent Growth Forecast (Quarterly) - Merged Data (Fred Series Data & Phoenix Market Data).xlsx')\n",
    "merged_data_file_path = os.path.abspath(f'{fred_data_directory}\\\\Rent Growth Forecast (Annual) - Merged Data (Fred Series Data & Phoenix Market Data).xlsx')\n",
    "merged_data = pd.read_excel(merged_data_file_path)\n",
    "merged_data.dropna(inplace=True)\n",
    "\n",
    "# Handle missing values with forward fill\n",
    "df_filled = merged_data.fillna(method='ffill')\n",
    "\n",
    "\n",
    "#################################### Add interaction terms ####################################\n",
    "##### Interaction Type - Multiplication\n",
    "df_filled['Job-Population Interaction'] = df_filled['Job Growth (%)'] * df_filled['Population Growth (%)']\n",
    "df_filled['Income-Population Interaction'] = df_filled['Median Household Income Growth (%)'] * df_filled['Population Growth (%)']\n",
    "df_filled['Job-Income Interaction'] = df_filled['Job Growth (%)'] * df_filled['Median Household Income Growth (%)']\n",
    "df_filled['Job-Under Construction Interaction'] = df_filled['Job Growth (%)'] * df_filled['Under Construction (% of Inventory)']\n",
    "df_filled['Population-Under Construction Interaction'] = df_filled['Population Growth (%)'] * df_filled['Under Construction (% of Inventory)']\n",
    "\n",
    "##### Interaction Type - Division\n",
    "df_filled['Absorption-Deliveries Interaction'] = df_filled['Absorption - Prior 12 Months (# Units)'] / df_filled['Net Deliveries - Prior 12 Months (# Units)']\n",
    "# df_filled['Absorption-Deliveries Interaction'] = df_filled['Quarterly Net Absorption (# Units)'] / df_filled['Quarterly Net Deliveries (# Units)']\n",
    "\n",
    "df_filled['Under Construction-Inventory Interaction'] = df_filled['Under Construction (# Units)'] / df_filled['Inventory (# Units)']\n",
    "df_filled['Deliveries-Inventory Interaction'] = df_filled['Net Deliveries - Prior 12 Months (# Units)'] / df_filled['Inventory (# Units)']\n",
    "# df_filled['Deliveries-Inventory Interaction'] = df_filled['Quarterly Net Deliveries (# Units)'] / df_filled['Inventory (# Units)']\n",
    "\n",
    "df_filled['Occupancy-Inventory Interaction'] = df_filled['Total Occupancy (# Units)'] / df_filled['Inventory (# Units)']\n",
    "df_filled['Vacancy-Inventory Interaction'] = df_filled['Total Vacancy (# Units)'] / df_filled['Inventory (# Units)']\n",
    "df_filled['Unemployed-Labor Force Interaction'] = df_filled['Unemployed Persons in Phoenix-Mesa-Scottsdale, AZ (MSA)'] / df_filled['Civilian Labor Force in Phoenix-Mesa-Scottsdale, AZ (MSA)']\n",
    "df_filled['Employed-Labor Force Interaction'] = df_filled['Employed Persons in Phoenix-Mesa-Scottsdale, AZ (MSA)'] / df_filled['Civilian Labor Force in Phoenix-Mesa-Scottsdale, AZ (MSA)']\n",
    "\n",
    "\n",
    "# Add lagged variables for independent variables\n",
    "# df_filled['Unemployment Rate Lagged'] = df_filled['Unemployment Rate (%)'].shift(1)\n",
    "# df_filled['Job Growth Lagged'] = df_filled['Job Growth (%)'].shift(1)\n",
    "# df_filled['Population Growth Lagged'] = df_filled['Population Growth (%)'].shift(1)\n",
    "\n",
    "df_filled['Unemployment Rate Lagged'] = df_filled['Unemployment Rate (%)'].shift(4)\n",
    "df_filled['Job Growth Lagged'] = df_filled['Job Growth (%)'].shift(4)\n",
    "df_filled['Population Growth Lagged'] = df_filled['Population Growth (%)'].shift(4)\n",
    "\n",
    "\n",
    "# Drop rows with NaN values caused by lagging\n",
    "df_filled = df_filled.dropna()\n",
    "\n",
    "# Define independent and dependent variables\n",
    "X = df_filled[[\n",
    "    'Job-Population Interaction',\n",
    "    'Income-Population Interaction',\n",
    "    'Job-Income Interaction',\n",
    "    'Job-Under Construction Interaction',\n",
    "    'Population-Under Construction Interaction',\n",
    "\n",
    "    'Absorption-Deliveries Interaction',\n",
    "    'Under Construction-Inventory Interaction',\n",
    "    'Deliveries-Inventory Interaction',\n",
    "\n",
    "    'Occupancy-Inventory Interaction',\n",
    "    'Vacancy-Inventory Interaction',\n",
    "    'Unemployed-Labor Force Interaction',\n",
    "    'Employed-Labor Force Interaction',\n",
    "    \n",
    "    # 'Annual Rent Growth (%) - Lagged',\n",
    "    'Unemployment Rate Lagged',\n",
    "    'Job Growth Lagged',\n",
    "    'Population Growth Lagged',\n",
    "\n",
    "    # 'Inventory (# Units)',\n",
    "    # 'Under Construction (# Units)',\n",
    "    'Under Construction (% of Inventory)',\n",
    "    'Absorption - Prior 12 Months (# Units)', \n",
    "    # 'Quarterly Net Absorption (# Units)',\n",
    "    'Net Deliveries - Prior 12 Months (# Units)',\n",
    "    # 'Quarterly Net Deliveries (# Units)',\n",
    "\n",
    "    # 'Unemployment Rate (%)',\n",
    "    # 'Job Growth (%)',\n",
    "    # 'Population (#)',\n",
    "    # 'Population Growth (%)', \n",
    "    'Median Household Income ($)',\n",
    "    'Median Household Income Growth (%)',\n",
    "               ]]\n",
    "\n",
    "y = df_filled['Annual Rent Growth (%)']\n",
    "\n",
    "# Add constant for the regression intercept\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "\n",
    "\n",
    "##################################################################\n",
    "# ------------------ 1. Out-of-Sample Testing ------------------ #\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Ridge regression with cross-validation hyperparameter tuning\n",
    "ridge_params = {'alpha': [0.01, 0.1, 1.0, 10, 100]}\n",
    "ridge_model = Ridge()\n",
    "ridge_cv = GridSearchCV(ridge_model, ridge_params, cv=TimeSeriesSplit(n_splits=5), scoring='r2')\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "# Best model from cross-validation\n",
    "ridge_best = ridge_cv.best_estimator_\n",
    "\n",
    "# Predictions on test set\n",
    "ridge_predictions_train = ridge_best.predict(X_train)\n",
    "ridge_predictions_test = ridge_best.predict(X_test)\n",
    "\n",
    "# Ridge model performance\n",
    "train_r2 = r2_score(y_train, ridge_predictions_train)\n",
    "test_r2 = r2_score(y_test, ridge_predictions_test)\n",
    "\n",
    "# Residual analysis\n",
    "residuals = y_test - ridge_predictions_test\n",
    "# print(\"Residuals summary:\")\n",
    "# print(residuals.describe())\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# ------------------ 2. Vector Autoregression (VAR) ------------------ #\n",
    "# Create VAR model using key time series\n",
    "df_var = df_filled[[\n",
    "    'Annual Rent Growth (%)',\n",
    "\n",
    "    'Job-Population Interaction',\n",
    "    'Income-Population Interaction',\n",
    "    'Job-Income Interaction',\n",
    "    'Job-Under Construction Interaction',\n",
    "    'Population-Under Construction Interaction',\n",
    "\n",
    "    'Absorption-Deliveries Interaction',\n",
    "    'Under Construction-Inventory Interaction',\n",
    "    'Deliveries-Inventory Interaction',\n",
    "\n",
    "    'Occupancy-Inventory Interaction',\n",
    "    'Vacancy-Inventory Interaction',\n",
    "    'Unemployed-Labor Force Interaction',\n",
    "    'Employed-Labor Force Interaction',\n",
    "\n",
    "    'Unemployment Rate Lagged',\n",
    "    'Job Growth Lagged',\n",
    "    'Population Growth Lagged',\n",
    "\n",
    "    'Under Construction (% of Inventory)',\n",
    "\n",
    "    'Absorption - Prior 12 Months (# Units)', \n",
    "    # 'Quarterly Net Absorption (# Units)',\n",
    "    'Net Deliveries - Prior 12 Months (# Units)',\n",
    "    # 'Quarterly Net Deliveries (# Units)',\n",
    "\n",
    "    'Unemployment Rate (%)',\n",
    "    'Job Growth (%)',\n",
    "    'Population Growth (%)', \n",
    "    'Median Household Income Growth (%)',\n",
    "    ]]\n",
    "model_var = VAR(df_var)\n",
    "var_results = model_var.fit(maxlags=2)\n",
    "\n",
    "# Forecast periods using VAR\n",
    "# var_forecast_periods = 5\n",
    "var_forecast_periods = 10\n",
    "# var_forecast_periods = 20\n",
    "\n",
    "var_forecast = var_results.forecast(df_var.values[-var_results.k_ar:], steps=var_forecast_periods)\n",
    "var_forecast_df = pd.DataFrame(var_forecast, columns=df_var.columns)\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "# ------------------ 3. ARIMA Time Series Forecasting ------------------ #\n",
    "# Differencing to make the data stationary\n",
    "df_filled['Annual Rent Growth Diff'] = df_filled['Annual Rent Growth (%)'].diff().dropna()\n",
    "\n",
    "# ARIMA model (order based on dataset properties, p=1, d=1, q=1 as an example)\n",
    "arima_model = ARIMA(df_filled['Annual Rent Growth (%)'].dropna(), order=(1, 1, 1))\n",
    "arima_results = arima_model.fit()\n",
    "\n",
    "# future_periods = 5\n",
    "future_periods = 10\n",
    "# future_periods = 20\n",
    "\n",
    "arima_forecast = arima_results.forecast(steps=future_periods)\n",
    "\n",
    "\n",
    "# Create future dates for the forecast\n",
    "last_dataset_date = df_filled['Analysis Date'].max()\n",
    "first_future_date = pd._libs.tslibs.timestamps.Timestamp(year=last_dataset_date.year + 1, month=last_dataset_date.month, day=last_dataset_date.day)\n",
    "\n",
    "# future_dates = pd.date_range(start=first_future_date, periods=future_periods, freq='A', inclusive='right')\n",
    "future_dates = pd.date_range(start=first_future_date, periods=future_periods, freq='YE', inclusive='right')\n",
    "\n",
    "\n",
    "# Combine future dates and ARIMA forecast values\n",
    "arima_forecast_df = pd.DataFrame({\n",
    "    'Forecasted Date': future_dates,\n",
    "    'ARIMA Forecasted Rent Growth (%)': arima_forecast\n",
    "})\n",
    "\n",
    "arima_forecast_df.reset_index(inplace=True)\n",
    "arima_forecast_df.drop(columns=[\"index\"], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "############################################################################\n",
    "# ------------------ 4. Random Forest (Ensemble Method) ------------------ #\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Random forest performance\n",
    "rf_r2 = r2_score(y_test, rf_predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# ------------------ 5. LSTM Neural Network for Time Series ------------------ #\n",
    "\n",
    "# Set environment variables for threads (similar idea to TensorFlow's environment vars)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"  # Controls OpenMP threads\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"4\"  # For MKL (if used internally)\n",
    "\n",
    "# Then in your Python code:\n",
    "torch.set_num_threads(4)  # Ensures PyTorch uses 2 threads internally\n",
    "\n",
    "\n",
    "# Create a custom pytorch dataset and retun a dataloader\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch dataset for creating sequences of length `time_steps`\n",
    "    from a 2D feature array X and 1D array y.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, time_steps):\n",
    "        \"\"\"\n",
    "        X: numpy array of shape [num_samples, num_features]\n",
    "        y: numpy array of shape [num_samples]\n",
    "        time_steps: int, number of past timesteps to include in each sample\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.time_steps = time_steps\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of valid sequences = total samples - time_steps\n",
    "        return len(self.X) - self.time_steps\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Sequences range from idx to idx + time_steps\n",
    "        x_seq = self.X[idx : idx + self.time_steps]\n",
    "        y_label = self.y[idx + self.time_steps]  # label at the end of the window\n",
    "        # Convert to float32 tensors\n",
    "        x_seq = torch.tensor(x_seq, dtype=torch.float32)\n",
    "        y_label = torch.tensor(y_label, dtype=torch.float32)\n",
    "        return x_seq, y_label\n",
    "\n",
    "\n",
    "def create_torch_dataloader(X, y, time_steps, batch_size):\n",
    "    \"\"\"\n",
    "    Create a PyTorch DataLoader for time series data.\n",
    "    \"\"\"\n",
    "    dataset = TimeSeriesDataset(X, y, time_steps)\n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False,   # Typically don't shuffle time series\n",
    "        drop_last=False  # Keep all samples\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "# Scaling Data\n",
    "# Example: X, y are your original time series data\n",
    "# They can be NumPy arrays or Pandas DataFrame/Series.\n",
    "\n",
    "scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)  # shape: [samples, features]\n",
    "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMTimeSeriesModel(nn.Module):\n",
    "    def __init__(self, input_dim, lstm_units):\n",
    "        \"\"\"\n",
    "        input_dim : number of features per timestep\n",
    "        lstm_units: hidden dimension (number of LSTM units)\n",
    "        \"\"\"\n",
    "        super(LSTMTimeSeriesModel, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=input_dim, hidden_size=lstm_units, batch_first=True, dropout=0.0)\n",
    "        self.lstm2 = nn.LSTM(input_size=lstm_units, hidden_size=lstm_units, batch_first=True, dropout=0.0)\n",
    "        self.fc = nn.Linear(lstm_units, 1)  # Final dense layer -> 1 output\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, time_steps, input_dim]\n",
    "        out, (h, c) = self.lstm1(x)  # out shape: [batch_size, time_steps, lstm_units]\n",
    "        out, (h, c) = self.lstm2(out)  # out shape: [batch_size, time_steps, lstm_units]\n",
    "        # Take the last timestep's output\n",
    "        last_timestep = out[:, -1, :]  # shape: [batch_size, lstm_units]\n",
    "        return self.fc(last_timestep)  # shape: [batch_size, 1]\n",
    "\n",
    "\n",
    "# Train and evaluate the mnodel using the dataloader\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for x_batch, y_batch in dataloader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs.view(-1), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * x_batch.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    eval_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in dataloader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs.view(-1), y_batch)\n",
    "            eval_loss += loss.item() * x_batch.size(0)\n",
    "\n",
    "    eval_loss = eval_loss / len(dataloader.dataset)\n",
    "    return eval_loss\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "# -------- 6. Forecasting/Prediction with the Best Hyperparameters -------- #\n",
    "# Forecasting\n",
    "time_steps = 10\n",
    "num_epochs = 50\n",
    "\n",
    "\n",
    "def run_optuna_study(X_scaled, y_scaled, time_steps, num_epochs, n_splits=5, n_trials=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    def objective(trial):\n",
    "        # lstm_units = trial.suggest_int('lstm_units', 16, 64)\n",
    "        lstm_units = trial.suggest_int('lstm_units', 16, 128)        \n",
    "\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "\n",
    "        # batch_size = trial.suggest_categorical('batch_size', [16, 32])\n",
    "        batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
    "\n",
    "        avg_loss = 0.0\n",
    "        fold_count = 0\n",
    "\n",
    "        for train_idx, test_idx in tscv.split(X_scaled):\n",
    "            # Split data\n",
    "            X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "            y_train, y_test = y_scaled[train_idx], y_scaled[test_idx]\n",
    "            \n",
    "            # Create Dataloaders\n",
    "            train_loader = create_torch_dataloader(X_train, y_train, time_steps, batch_size)\n",
    "            test_loader  = create_torch_dataloader(X_test,  y_test,  time_steps, batch_size)\n",
    "            \n",
    "            # Build model\n",
    "            input_dim = X_train.shape[1]\n",
    "            model = LSTMTimeSeriesModel(input_dim=input_dim, lstm_units=lstm_units).to(device)\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "            \n",
    "            # Train model for num_epochs\n",
    "            for epoch in range(num_epochs):\n",
    "                train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            test_loss = evaluate(model, test_loader, criterion, device)\n",
    "            avg_loss += test_loss\n",
    "            fold_count += 1\n",
    "        \n",
    "        return avg_loss / fold_count\n",
    "\n",
    "    # Create and run the study\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=n_trials, n_jobs=-1)  # Parallel or single-thread\n",
    "\n",
    "    return study.best_params\n",
    "\n",
    "\n",
    "best_hyperparameters = run_optuna_study(X_scaled, y_scaled, time_steps, num_epochs, n_splits=5, n_trials=10)\n",
    "print(\"Best Hyperparams:\", best_hyperparameters)\n",
    "\n",
    "\n",
    "# Train the model using the best hyperparameters\n",
    "# Suppose you got these from `best_hyperparameters`\n",
    "num_lstm_units = best_hyperparameters['lstm_units']\n",
    "learning_rate  = best_hyperparameters['learning_rate']\n",
    "batch_size     = best_hyperparameters['batch_size']\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create a single DataLoader over the entire dataset\n",
    "full_loader = create_torch_dataloader(X_scaled, y_scaled, time_steps, batch_size)\n",
    "\n",
    "model_lstm = LSTMTimeSeriesModel(\n",
    "    input_dim=X_scaled.shape[1], \n",
    "    lstm_units=num_lstm_units\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model_lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "# num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch(model_lstm, full_loader, criterion, optimizer, device)\n",
    "    # If desired, implement an early stopping check here\n",
    "    # ...\n",
    "    # print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.6f}\")\n",
    "\n",
    "# Optionally save your final model weights\n",
    "checkpoint_filepath = os.path.abspath(r\"C:\\Users\\MattBorgeson\\OneDrive - B&R Capital\\Programming Projects\\Rent Growth Forecasting\\Output Files\\Best Model Weights/best_model_fold_torch (Quarterly).pt\")\n",
    "# checkpoint_filepath = os.path.abspath(\"best_model_fold_torch.pt\")\n",
    "torch.save(model_lstm.state_dict(), checkpoint_filepath)\n",
    "\n",
    "# To load them later:\n",
    "# model_lstm.load_state_dict(torch.load(checkpoint_filepath))\n",
    "# model_lstm.eval()\n",
    "\n",
    "\n",
    "# Autoregressive Forecasting with LSTM\n",
    "model_lstm.eval()\n",
    "\n",
    "last_sequence = X_scaled[-time_steps:].copy()  # shape: (time_steps, num_features)\n",
    "ml_optimized_predictions = []\n",
    "\n",
    "\n",
    "forecast_num_steps = 10  # e.g., 10 future steps\n",
    "for _ in range(forecast_num_steps):\n",
    "    # (1) Reshape for model: [batch_size=1, time_steps, num_features]\n",
    "    seq_input = torch.tensor(last_sequence, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    \n",
    "    # (2) Predict\n",
    "    with torch.no_grad():\n",
    "        next_value_scaled_tensor = model_lstm(seq_input)  # shape: [1, 1]\n",
    "    \n",
    "    next_value_scaled = next_value_scaled_tensor.cpu().numpy().reshape(-1, 1)\n",
    "    \n",
    "    # (3) Inverse transform from scaled to original\n",
    "    next_value_original_scale = scaler_y.inverse_transform(next_value_scaled)\n",
    "    ml_optimized_predictions.append(next_value_original_scale[0, 0])\n",
    "    \n",
    "    # (4) Update the last_sequence with this new predicted value\n",
    "    #     If your target is the 1st column, place it there:\n",
    "    next_features = np.zeros((1, last_sequence.shape[1]))\n",
    "    next_value_rescaled = scaler_y.transform(next_value_original_scale)  # scale back for model continuity\n",
    "    next_features[0, 0] = next_value_rescaled[0, 0]\n",
    "    \n",
    "    # Shift and append\n",
    "    last_sequence = np.vstack([last_sequence[1:], next_features])\n",
    "\n",
    "ml_optimized_forecast_df = arima_forecast_df.copy(deep=True)\n",
    "ml_optimized_forecast_df[\"Machine Learning Optimized Forecast\"] = ml_optimized_predictions\n",
    "ml_optimized_forecast_df.drop(columns=['ARIMA Forecasted Rent Growth (%)'], inplace=True, errors='ignore')\n",
    "ml_optimized_forecast_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############################################################\n",
    "# ------------------ 7. Summary & Outputs ------------------ #\n",
    "rent_growth_forecasts_df = arima_forecast_df.copy(deep=True)\n",
    "rent_growth_forecasts_df[\"Machine Learning Optimized Forecast\"] = list(ml_optimized_forecast_df[\"Machine Learning Optimized Forecast\"])\n",
    "rent_growth_forecasts_df['Vector Autoregression (VAR) Forecast'] = list(var_forecast_df['Annual Rent Growth (%)'])\n",
    "rent_growth_forecasts_df.rename(columns={'ARIMA Forecasted Rent Growth (%)':'ARIMA Forecast'}, inplace=True)\n",
    "\n",
    "\n",
    "# print(f\"Ridge Regression R^2 on Train: {train_r2}, Test: {test_r2}\")\n",
    "# print(f\"Random Forest R^2 on Test: {rf_r2}\")\n",
    "\n",
    "\n",
    "var_forecast_df.rename(columns={'Annual Rent Growth (%)':'Vector Autoregression (VAR) Forecast'}, inplace=True)\n",
    "print(\"Forecast Type -- Vector Autoregression Analysis\")\n",
    "print(\"Forecast Tools -- Statsmodels\")\n",
    "print(f\"VAR Forecast:\")\n",
    "print(var_forecast_df['Vector Autoregression (VAR) Forecast'])\n",
    "\n",
    "\n",
    "print(\"Forecast Type -- Autoregressive Integrated Moving Average (ARIMA) Analysis\")\n",
    "print(\"Forecast Tools -- Statsmodels\")\n",
    "print(f\"ARIMA Forecast:\")\n",
    "print(arima_forecast_df['ARIMA Forecasted Rent Growth (%)'])\n",
    "\n",
    "\n",
    "print(\"Forecast Type -- Machine Learning/Neural Network Forecasting Using Optimized Independent Variable/Parameter Weights\")\n",
    "print(\"Forecast Tools -- PyTorch & Optuna\")\n",
    "# print(f\"Forecasted values for the next {forecast_num_steps} time steps:\")\n",
    "print(f\"Machine Learning Optimized Forecast:\")\n",
    "print(ml_optimized_forecast_df[\"Machine Learning Optimized Forecast\"])\n",
    "\n",
    "\n",
    "# Save the Forecasts DataFrame with all forecasts to an Excel file\n",
    "forecasting_analysis_outputs_file_path = os.path.abspath(r'C:\\Users\\MattBorgeson\\OneDrive - B&R Capital\\Programming Projects\\Rent Growth Forecasting\\Output Files\\Forecasts')\n",
    "\n",
    "\n",
    "var_forecast_file_path = os.path.abspath(f'{forecasting_analysis_outputs_file_path}\\\\VAR Forecast Model Forecasts (Annual).xlsx')\n",
    "arima_forecast_file_path = os.path.abspath(f'{forecasting_analysis_outputs_file_path}\\\\ARIMA Forecast Model Forecasts (Annual).xlsx')\n",
    "ml_optimized_forecast_file_path = os.path.abspath(f'{forecasting_analysis_outputs_file_path}\\\\Machine Learning Forecast Model Forecasts (Annual).xlsx')\n",
    "all_forecasts_file_path = os.path.abspath(f'{forecasting_analysis_outputs_file_path}\\\\All Forecast Methodologies Forecasts (Annual).xlsx')\n",
    "\n",
    "\n",
    "# var_forecast_df.to_excel(var_forecast_file_path, index=False)\n",
    "# arima_forecast_df.to_excel(arima_forecast_file_path, index=False)\n",
    "# ml_optimized_forecast_df.to_excel(ml_optimized_forecast_file_path, index=False)\n",
    "rent_growth_forecasts_df.to_excel(all_forecasts_file_path, index=False)\n",
    "\n",
    "\n",
    "\n",
    "##############################################################\n",
    "# -------------------- 8. Code Run Time -------------------- #\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "elapsed_time = (elapsed_time/60)\n",
    "elapsed_time = round(elapsed_time, 2)\n",
    "print(f\"Elapsed time: {elapsed_time} minutes\")\n",
    "\n",
    "def code_completion_notification ():\n",
    "    engine = pyttsx3.init()\n",
    "    # engine.endLoop()    \n",
    "    \n",
    "    try:\n",
    "        engine.endLoop()\n",
    "        del engine\n",
    "        engine = pyttsx3.init()\n",
    "    except:\n",
    "        pass\n",
    "        code_run_time = f\"The code took {elapsed_time} minutes to run.\"\n",
    "        text = \"Annual Rent Growth Forecast Analysis Complete.\"\n",
    "        text = f\"{text} {code_run_time}\"\n",
    "\n",
    "        engine.setProperty('rate', 225)\n",
    "\n",
    "        volume = engine.getProperty('volume')\n",
    "        engine.setProperty('volume', volume+0.50)\n",
    "\n",
    "        winsound.Beep(750, 1250)\n",
    "        engine.say(text)\n",
    "\n",
    "        engine.startLoop(False)\n",
    "        engine.iterate()\n",
    "        engine.endLoop()        \n",
    "\n",
    "\n",
    "code_completion_notification ()\n",
    "# %run \"{python_files_folder}Annual Rent Growth Forecasts.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.A.4.5) SINGLE-CELL CONSOLIDATED CODE -- RUN RENT GROWTH FORECAST ANALYSES (ANNUAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"{python_files_folder}Annual Rent Growth Forecasts.py\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rent_growth_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
